{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mahdimplus/DeepRetroMoco/blob/main/network/train_with_validtiondatafunctions.ipynb)"
      ],
      "metadata": {
        "id": "CouPttSA0YgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "-rzBTKnjJmAs",
        "outputId": "113f629c-c137-4c27-f04b-d0742e8c3f3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "%cd /content\n",
        "!mkdir drive\n",
        "%cd drive\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "sMjV-kBrjccB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install voxelmorph\n"
      ],
      "metadata": {
        "id": "80X4he9ILFFL",
        "outputId": "e89e7fcd-2b7c-4367-8250-ddeb0fba2e6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting voxelmorph\n",
            "  Downloading voxelmorph-0.1-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▍                           | 10 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 20 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 30 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 75 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (3.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (1.21.5)\n",
            "Collecting neurite\n",
            "  Downloading neurite-0.1-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (1.4.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (0.18.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->voxelmorph) (1.5.2)\n",
            "Collecting pystrum\n",
            "  Downloading pystrum-0.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (0.11.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (1.2.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2021.11.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->neurite->voxelmorph) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->neurite->voxelmorph) (1.1.0)\n",
            "Installing collected packages: pystrum, neurite, voxelmorph\n",
            "Successfully installed neurite-0.1 pystrum-0.1 voxelmorph-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mXdTYidN0Tac"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "# local imports\n",
        "import voxelmorph as vxm\n",
        "import neurite as ne\n",
        "import os, sys\n",
        "\n",
        "# third party imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2.'), 'This tutorial assumes Tensorflow 2.0+'\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "import nibabel as nib\n",
        "\n",
        "#import nbimporter\n",
        "#from functions import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fzES90Vp0Tai"
      },
      "outputs": [],
      "source": [
        "#m=maxx(data_dir)\n",
        "m=1584 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def load_m (file_path):\n",
        "    \n",
        "    img = nib.load(file_path)\n",
        "    img_data = img.get_fdata()\n",
        "    \n",
        "    if img.shape[0:2]!=(64,64):\n",
        "    \n",
        "        img_data = img_data[23:87,23:87,:,:]\n",
        "        \n",
        "    if not (file_path.endswith(\".nii\") or file_path.endswith(\".nii.gz\")):\n",
        "        raise ValueError(\n",
        "              f\"Nifti file path must end with .nii or .nii.gz, got {file_path}.\"\n",
        "                        )\n",
        "    return img_data \n",
        "def count (data_dir):\n",
        "    train_dir = os.path.join(data_dir)\n",
        "\n",
        "    train_data_num = []\n",
        "    for file in os.listdir(train_dir):\n",
        "            train_data_num.append([file])\n",
        "    train_data_num=np.array(train_data_num) \n",
        "    n=train_data_num.shape[0] \n",
        "\n",
        "    return n,train_data_num"
      ],
      "metadata": {
        "id": "B4ghNO6uS9Fw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(data_dir, batch_size,m,split):\n",
        "    \"\"\"4\n",
        "    Generator that takes in data of size [N, H, W], and yields data for\n",
        "    our custom vxm model. Note that we need to provide numpy data for each\n",
        "    input, and each output.\n",
        "\n",
        "    inputs:  moving [bs, H, W, 1], fixed image [bs, H, W, 1]\n",
        "    outputs: moved image [bs, H, W, 1], zero-gradient [bs, H, W, 2]\n",
        "    \n",
        "    m= maximum between all subject \n",
        "    split= percent of validation data\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    n,train_data_num=count(data_dir)\n",
        "    n_train=n-int(split*n)\n",
        " \n",
        "    \n",
        "    subject_ID=random.randint(0,n_train-1)\n",
        "    d=load_m(data_dir+'/'+str(train_data_num[subject_ID][0]))\n",
        "\n",
        "    \n",
        "    s=d.shape[2]\n",
        "    slice_ID =random.randint(0,s-1)\n",
        "    v=d.shape[3]\n",
        "    \n",
        " # preliminary sizing\n",
        "    vol_shape = d.shape[:2] # extract data shape\n",
        "    ndims = len(vol_shape)\n",
        "    \n",
        "    \n",
        "    d=d[:,:,slice_ID,:]\n",
        "    d = np.einsum('jki->ijk', d)\n",
        "\n",
        "    \n",
        "    \n",
        "   \n",
        "    \n",
        "    # prepare a zero array the size of the deformation\n",
        "    # we'll explain this below\n",
        "    zero_phi = np.zeros([batch_size, *vol_shape, ndims])\n",
        "    \n",
        "    while True:\n",
        "        # prepare inputs:\n",
        "        # images need to be of the size [batch_size, H, W, 1]\n",
        "        idx1 = np.random.randint(0, v, size=batch_size)\n",
        "        moving_images = d[idx1, ..., np.newaxis]\n",
        "        moving_images=moving_images/m\n",
        "        \n",
        "        idx2 = np.random.randint(0, v, size=batch_size)\n",
        "        fixed_images = d[idx2, ..., np.newaxis]\n",
        "        fixed_images=fixed_images/m\n",
        "        \n",
        "        inputs = [moving_images, fixed_images]\n",
        "        \n",
        "        # prepare outputs (the 'true' moved image):\n",
        "        # of course, we don't have this, but we know we want to compare \n",
        "        # the resulting moved image with the fixed image. \n",
        "        # we also wish to penalize the deformation field. \n",
        "        outputs = [fixed_images, zero_phi]\n",
        "        \n",
        "        yield (inputs, outputs)\n",
        "\n",
        "\n",
        "\n",
        "def val_generator(data_dir, batch_size,m,split):\n",
        "  \n",
        "    n,train_data_num=count(data_dir)\n",
        "    n_train=n-int(split*n)\n",
        "    a=n_train\n",
        "    \n",
        "    \n",
        "    subject_ID=random.randint(a,n-1)\n",
        "    d=load_m(data_dir+'/'+str(train_data_num[subject_ID][0]))\n",
        "\n",
        "    \n",
        "    s=d.shape[2]\n",
        "    slice_ID =random.randint(0,s-1)\n",
        "    v=d.shape[3]\n",
        "    \n",
        "    # preliminary sizing\n",
        "    vol_shape = d.shape[:2] # extract data shape\n",
        "    ndims = len(vol_shape)\n",
        "    \n",
        "    \n",
        "    d=d[:,:,slice_ID,:]\n",
        "    d = np.einsum('jki->ijk', d)\n",
        "\n",
        " \n",
        "    # prepare a zero array the size of the deformation\n",
        "    # we'll explain this below\n",
        "    zero_phi = np.zeros([batch_size, *vol_shape, ndims])\n",
        "    \n",
        "    # prepare inputs:\n",
        "    # images need to be of the size [batch_size, H, W, 1]\n",
        "    idx1 = np.random.randint(0, v, size=batch_size)\n",
        "    moving_images = d[idx1, ..., np.newaxis]\n",
        "    moving_images=moving_images/m\n",
        "\n",
        "    idx2 = np.random.randint(0, v, size=batch_size)\n",
        "    fixed_images = d[idx2, ..., np.newaxis]\n",
        "    fixed_images=fixed_images/m\n",
        "\n",
        "    inputs = [moving_images, fixed_images]\n",
        "\n",
        "    # prepare outputs (the 'true' moved image):\n",
        "    # of course, we don't have this, but we know we want to compare \n",
        "    # the resulting moved image with the fixed image. \n",
        "    # we also wish to penalize the deformation field. \n",
        "    outputs = [fixed_images,zero_phi]\n",
        "\n",
        "    return (inputs, outputs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KPxDR9SZSxxi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir='/content/drive/MyDrive/data/data selection_D1'"
      ],
      "metadata": {
        "id": "SSerd10qT06W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I9b6tv3m0Taj",
        "outputId": "24ea0df6-6e95-4d3a-aefc-45a9564bc1ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x270 with 8 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "split=0.3  # it means 70% for train and 30% for validation\n",
        "\n",
        "\n",
        "train_generator = data_generator(data_dir,100,m,split)\n",
        "in_sample, out_sample = next(train_generator)\n",
        "\n",
        "# visualize\n",
        "images = [img[0, :, :, 0] for img in in_sample + out_sample] \n",
        "titles = ['moving', 'fixed', 'moved ground-truth (fixed)', 'zeros']\n",
        "ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bwSxd8fu0Tal"
      },
      "outputs": [],
      "source": [
        "# configure unet input shape (concatenation of moving and fixed images)\n",
        "ndim = 2\n",
        "unet_input_features = 2\n",
        "# data shape 64*64\n",
        "s=in_sample[0].shape[1:3]\n",
        "inshape = (*s, unet_input_features)\n",
        "\n",
        "# configure unet features \n",
        "nb_features = [\n",
        "    [64, 64, 64, 64],         # encoder features\n",
        "    [64, 64, 64, 64, 64, 32,16]  # decoder features\n",
        "]\n",
        "\n",
        "#nb_features = [\n",
        "#    [32, 32, 32, 32],         # encoder features\n",
        "#    [32, 32, 32, 32, 32,16]  # decoder features\n",
        "#           ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vN0tjwud0Tam",
        "outputId": "4440bf2f-1e28-44ea-da00-a2451f8a252b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6JVD05Hx0Tan",
        "outputId": "16970cea-dca4-466c-f0da-d977e9eeda6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        }
      ],
      "source": [
        "# build model using VxmDense\n",
        "inshape =s\n",
        "vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "scrolled": true,
        "id": "U-dO1Opg0Tap",
        "outputId": "2637fdb0-3da3-48f0-f080-7e7132d223ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vxm_dense\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " source_input (InputLayer)      [(None, 64, 64, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " target_input (InputLayer)      [(None, 64, 64, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " unet_input_concat (Concatenate  (None, 64, 64, 2)   0           ['source_input[0][0]',           \n",
            " )                                                                'target_input[0][0]']           \n",
            "                                                                                                  \n",
            " unet_enc_conv_0_0 (Conv2D)     (None, 64, 64, 64)   1216        ['unet_input_concat[0][0]']      \n",
            "                                                                                                  \n",
            " unet_enc_conv_0_0_activation (  (None, 64, 64, 64)  0           ['unet_enc_conv_0_0[0][0]']      \n",
            " LeakyReLU)                                                                                       \n",
            "                                                                                                  \n",
            " unet_enc_pooling_0 (MaxPooling  (None, 32, 32, 64)  0           ['unet_enc_conv_0_0_activation[0]\n",
            " 2D)                                                             [0]']                            \n",
            "                                                                                                  \n",
            " unet_enc_conv_1_0 (Conv2D)     (None, 32, 32, 64)   36928       ['unet_enc_pooling_0[0][0]']     \n",
            "                                                                                                  \n",
            " unet_enc_conv_1_0_activation (  (None, 32, 32, 64)  0           ['unet_enc_conv_1_0[0][0]']      \n",
            " LeakyReLU)                                                                                       \n",
            "                                                                                                  \n",
            " unet_enc_pooling_1 (MaxPooling  (None, 16, 16, 64)  0           ['unet_enc_conv_1_0_activation[0]\n",
            " 2D)                                                             [0]']                            \n",
            "                                                                                                  \n",
            " unet_enc_conv_2_0 (Conv2D)     (None, 16, 16, 64)   36928       ['unet_enc_pooling_1[0][0]']     \n",
            "                                                                                                  \n",
            " unet_enc_conv_2_0_activation (  (None, 16, 16, 64)  0           ['unet_enc_conv_2_0[0][0]']      \n",
            " LeakyReLU)                                                                                       \n",
            "                                                                                                  \n",
            " unet_enc_pooling_2 (MaxPooling  (None, 8, 8, 64)    0           ['unet_enc_conv_2_0_activation[0]\n",
            " 2D)                                                             [0]']                            \n",
            "                                                                                                  \n",
            " unet_enc_conv_3_0 (Conv2D)     (None, 8, 8, 64)     36928       ['unet_enc_pooling_2[0][0]']     \n",
            "                                                                                                  \n",
            " unet_enc_conv_3_0_activation (  (None, 8, 8, 64)    0           ['unet_enc_conv_3_0[0][0]']      \n",
            " LeakyReLU)                                                                                       \n",
            "                                                                                                  \n",
            " unet_enc_pooling_3 (MaxPooling  (None, 4, 4, 64)    0           ['unet_enc_conv_3_0_activation[0]\n",
            " 2D)                                                             [0]']                            \n",
            "                                                                                                  \n",
            " unet_dec_conv_3_0 (Conv2D)     (None, 4, 4, 64)     36928       ['unet_enc_pooling_3[0][0]']     \n",
            "                                                                                                  \n",
            " unet_dec_conv_3_0_activation (  (None, 4, 4, 64)    0           ['unet_dec_conv_3_0[0][0]']      \n",
            " LeakyReLU)                                                                                       \n",
            "                                                                                                  \n",
            " unet_dec_upsample_3 (UpSamplin  (None, 8, 8, 64)    0           ['unet_dec_conv_3_0_activation[0]\n",
            " g2D)                                                            [0]']                            \n",
            "                                                                                                  \n",
            " unet_dec_upsample_3_concat (Co  (None, 8, 8, 128)   0           ['unet_dec_upsample_3[0][0]',    \n",
            " ncatenate)                                                       'unet_enc_conv_3_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " unet_dec_conv_2_0 (Conv2D)     (None, 8, 8, 64)     73792       ['unet_dec_upsample_3_concat[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " unet_dec_conv_2_0_activation (  (None, 8, 8, 64)    0           ['unet_dec_conv_2_0[0][0]']      \n",
            " LeakyReLU)                                                                                       \n",
            "                                                                                                  \n",
            " unet_dec_upsample_2 (UpSamplin  (None, 16, 16, 64)  0           ['unet_dec_conv_2_0_activation[0]\n",
            " g2D)                                                            [0]']                            \n",
            "                                                                                                  \n",
            " unet_dec_upsample_2_concat (Co  (None, 16, 16, 128)  0          ['unet_dec_upsample_2[0][0]',    \n",
            " ncatenate)                                                       'unet_enc_conv_2_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " unet_dec_conv_1_0 (Conv2D)     (None, 16, 16, 64)   73792       ['unet_dec_upsample_2_concat[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " unet_dec_conv_1_0_activation (  (None, 16, 16, 64)  0           ['unet_dec_conv_1_0[0][0]']      \n",
            " LeakyReLU)                                                                                       \n",
            "                                                                                                  \n",
            " unet_dec_upsample_1 (UpSamplin  (None, 32, 32, 64)  0           ['unet_dec_conv_1_0_activation[0]\n",
            " g2D)                                                            [0]']                            \n",
            "                                                                                                  \n",
            " unet_dec_upsample_1_concat (Co  (None, 32, 32, 128)  0          ['unet_dec_upsample_1[0][0]',    \n",
            " ncatenate)                                                       'unet_enc_conv_1_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " unet_dec_conv_0_0 (Conv2D)     (None, 32, 32, 64)   73792       ['unet_dec_upsample_1_concat[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " unet_dec_conv_0_0_activation (  (None, 32, 32, 64)  0           ['unet_dec_conv_0_0[0][0]']      \n",
            " LeakyReLU)                                                                                       \n",
            "                                                                                                  \n",
            " unet_dec_upsample_0 (UpSamplin  (None, 64, 64, 64)  0           ['unet_dec_conv_0_0_activation[0]\n",
            " g2D)                                                            [0]']                            \n",
            "                                                                                                  \n",
            " unet_dec_upsample_0_concat (Co  (None, 64, 64, 128)  0          ['unet_dec_upsample_0[0][0]',    \n",
            " ncatenate)                                                       'unet_enc_conv_0_0_activation[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " unet_dec_final_conv_0 (Conv2D)  (None, 64, 64, 64)  73792       ['unet_dec_upsample_0_concat[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " unet_dec_final_conv_0_activati  (None, 64, 64, 64)  0           ['unet_dec_final_conv_0[0][0]']  \n",
            " on (LeakyReLU)                                                                                   \n",
            "                                                                                                  \n",
            " unet_dec_final_conv_1 (Conv2D)  (None, 64, 64, 32)  18464       ['unet_dec_final_conv_0_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " unet_dec_final_conv_1_activati  (None, 64, 64, 32)  0           ['unet_dec_final_conv_1[0][0]']  \n",
            " on (LeakyReLU)                                                                                   \n",
            "                                                                                                  \n",
            " unet_dec_final_conv_2 (Conv2D)  (None, 64, 64, 16)  4624        ['unet_dec_final_conv_1_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " unet_dec_final_conv_2_activati  (None, 64, 64, 16)  0           ['unet_dec_final_conv_2[0][0]']  \n",
            " on (LeakyReLU)                                                                                   \n",
            "                                                                                                  \n",
            " flow (Conv2D)                  (None, 64, 64, 2)    290         ['unet_dec_final_conv_2_activatio\n",
            "                                                                 n[0][0]']                        \n",
            "                                                                                                  \n",
            " transformer (SpatialTransforme  (None, 64, 64, 1)   0           ['source_input[0][0]',           \n",
            " r)                                                               'flow[0][0]']                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 467,474\n",
            "Trainable params: 467,474\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vxm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4_aLG24o0Taq"
      },
      "outputs": [],
      "source": [
        "# voxelmorph has a variety of custom loss classes\n",
        "losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
        "\n",
        "# usually, we have to balance the two losses by a hyper-parameter\n",
        "lambda_param = 0\n",
        "loss_weights = [1, lambda_param]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iLSulsKn0Tar"
      },
      "outputs": [],
      "source": [
        "vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PwmPqwEA0Tar"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,EarlyStopping\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1, patience=5, verbose=1)\n",
        "#annealer = ReduceLROnPlateau(monitor=['val_accuracy','val_mse'] ,factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
        "checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "scrolled": true,
        "id": "Mwpi1kcX0Tas",
        "outputId": "c236004b-877f-4494-b443-2bbe78b55aa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.00061, saving model to model.h5\n",
            "100/100 - 76s - loss: 0.0010 - transformer_loss: 0.0010 - flow_loss: 0.0014 - transformer_accuracy: 2.4829e-05 - flow_accuracy: 0.4506 - val_loss: 6.1243e-04 - val_transformer_loss: 6.1243e-04 - val_flow_loss: 0.0023 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.0356 - 76s/epoch - 764ms/step\n",
            "Epoch 2/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 2: val_loss improved from 0.00061 to 0.00054, saving model to model.h5\n",
            "100/100 - 59s - loss: 6.5697e-04 - transformer_loss: 6.5697e-04 - flow_loss: 0.0064 - transformer_accuracy: 2.4097e-05 - flow_accuracy: 0.4633 - val_loss: 5.3979e-04 - val_transformer_loss: 5.3979e-04 - val_flow_loss: 0.0055 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.1028 - 59s/epoch - 587ms/step\n",
            "Epoch 3/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 3: val_loss improved from 0.00054 to 0.00051, saving model to model.h5\n",
            "100/100 - 54s - loss: 5.5615e-04 - transformer_loss: 5.5615e-04 - flow_loss: 0.0195 - transformer_accuracy: 2.4219e-05 - flow_accuracy: 0.4731 - val_loss: 5.0558e-04 - val_transformer_loss: 5.0558e-04 - val_flow_loss: 0.0109 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3430 - 54s/epoch - 538ms/step\n",
            "Epoch 4/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 4: val_loss improved from 0.00051 to 0.00047, saving model to model.h5\n",
            "100/100 - 53s - loss: 5.0329e-04 - transformer_loss: 5.0329e-04 - flow_loss: 0.0355 - transformer_accuracy: 2.3877e-05 - flow_accuracy: 0.4777 - val_loss: 4.6636e-04 - val_transformer_loss: 4.6636e-04 - val_flow_loss: 0.0190 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.2893 - 53s/epoch - 530ms/step\n",
            "Epoch 5/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 5: val_loss improved from 0.00047 to 0.00044, saving model to model.h5\n",
            "100/100 - 53s - loss: 4.6665e-04 - transformer_loss: 4.6665e-04 - flow_loss: 0.0518 - transformer_accuracy: 2.4243e-05 - flow_accuracy: 0.4765 - val_loss: 4.3518e-04 - val_transformer_loss: 4.3518e-04 - val_flow_loss: 0.0282 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.1807 - 53s/epoch - 527ms/step\n",
            "Epoch 6/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 6: val_loss improved from 0.00044 to 0.00040, saving model to model.h5\n",
            "100/100 - 53s - loss: 4.3396e-04 - transformer_loss: 4.3396e-04 - flow_loss: 0.0698 - transformer_accuracy: 2.5439e-05 - flow_accuracy: 0.4711 - val_loss: 4.0314e-04 - val_transformer_loss: 4.0314e-04 - val_flow_loss: 0.0417 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3403 - 53s/epoch - 527ms/step\n",
            "Epoch 7/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 7: val_loss improved from 0.00040 to 0.00037, saving model to model.h5\n",
            "100/100 - 53s - loss: 4.0312e-04 - transformer_loss: 4.0312e-04 - flow_loss: 0.0921 - transformer_accuracy: 2.4536e-05 - flow_accuracy: 0.4706 - val_loss: 3.7247e-04 - val_transformer_loss: 3.7247e-04 - val_flow_loss: 0.0558 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3181 - 53s/epoch - 527ms/step\n",
            "Epoch 8/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 8: val_loss improved from 0.00037 to 0.00035, saving model to model.h5\n",
            "100/100 - 53s - loss: 3.7647e-04 - transformer_loss: 3.7647e-04 - flow_loss: 0.1206 - transformer_accuracy: 2.5073e-05 - flow_accuracy: 0.4615 - val_loss: 3.5157e-04 - val_transformer_loss: 3.5157e-04 - val_flow_loss: 0.0715 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3213 - 53s/epoch - 532ms/step\n",
            "Epoch 9/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 9: val_loss improved from 0.00035 to 0.00032, saving model to model.h5\n",
            "100/100 - 53s - loss: 3.4735e-04 - transformer_loss: 3.4735e-04 - flow_loss: 0.1578 - transformer_accuracy: 2.3682e-05 - flow_accuracy: 0.4650 - val_loss: 3.1938e-04 - val_transformer_loss: 3.1938e-04 - val_flow_loss: 0.1039 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3911 - 53s/epoch - 530ms/step\n",
            "Epoch 10/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 10: val_loss improved from 0.00032 to 0.00030, saving model to model.h5\n",
            "100/100 - 53s - loss: 3.2353e-04 - transformer_loss: 3.2353e-04 - flow_loss: 0.2008 - transformer_accuracy: 2.4194e-05 - flow_accuracy: 0.4625 - val_loss: 2.9974e-04 - val_transformer_loss: 2.9974e-04 - val_flow_loss: 0.1221 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3960 - 53s/epoch - 531ms/step\n",
            "Epoch 11/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 11: val_loss improved from 0.00030 to 0.00028, saving model to model.h5\n",
            "100/100 - 53s - loss: 3.0489e-04 - transformer_loss: 3.0489e-04 - flow_loss: 0.2434 - transformer_accuracy: 2.4658e-05 - flow_accuracy: 0.4672 - val_loss: 2.8102e-04 - val_transformer_loss: 2.8102e-04 - val_flow_loss: 0.1468 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3408 - 53s/epoch - 531ms/step\n",
            "Epoch 12/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 12: val_loss improved from 0.00028 to 0.00027, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.8720e-04 - transformer_loss: 2.8720e-04 - flow_loss: 0.2794 - transformer_accuracy: 2.5464e-05 - flow_accuracy: 0.4734 - val_loss: 2.6918e-04 - val_transformer_loss: 2.6918e-04 - val_flow_loss: 0.1706 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3743 - 53s/epoch - 532ms/step\n",
            "Epoch 13/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 13: val_loss improved from 0.00027 to 0.00026, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.7617e-04 - transformer_loss: 2.7617e-04 - flow_loss: 0.3112 - transformer_accuracy: 2.4341e-05 - flow_accuracy: 0.4772 - val_loss: 2.5815e-04 - val_transformer_loss: 2.5815e-04 - val_flow_loss: 0.1872 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3936 - 53s/epoch - 532ms/step\n",
            "Epoch 14/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 14: val_loss improved from 0.00026 to 0.00025, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.6519e-04 - transformer_loss: 2.6519e-04 - flow_loss: 0.3383 - transformer_accuracy: 2.5293e-05 - flow_accuracy: 0.4819 - val_loss: 2.4986e-04 - val_transformer_loss: 2.4986e-04 - val_flow_loss: 0.1953 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3821 - 53s/epoch - 531ms/step\n",
            "Epoch 15/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 15: val_loss improved from 0.00025 to 0.00024, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.5688e-04 - transformer_loss: 2.5688e-04 - flow_loss: 0.3575 - transformer_accuracy: 2.4170e-05 - flow_accuracy: 0.4835 - val_loss: 2.4145e-04 - val_transformer_loss: 2.4145e-04 - val_flow_loss: 0.2094 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4417 - 53s/epoch - 532ms/step\n",
            "Epoch 16/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 16: val_loss improved from 0.00024 to 0.00024, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.4930e-04 - transformer_loss: 2.4930e-04 - flow_loss: 0.3759 - transformer_accuracy: 2.4805e-05 - flow_accuracy: 0.4850 - val_loss: 2.3704e-04 - val_transformer_loss: 2.3704e-04 - val_flow_loss: 0.2189 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4229 - 53s/epoch - 530ms/step\n",
            "Epoch 17/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 17: val_loss improved from 0.00024 to 0.00024, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.4236e-04 - transformer_loss: 2.4236e-04 - flow_loss: 0.3890 - transformer_accuracy: 2.4683e-05 - flow_accuracy: 0.4849 - val_loss: 2.3529e-04 - val_transformer_loss: 2.3529e-04 - val_flow_loss: 0.2125 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3711 - 53s/epoch - 531ms/step\n",
            "Epoch 18/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 18: val_loss improved from 0.00024 to 0.00023, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.3646e-04 - transformer_loss: 2.3646e-04 - flow_loss: 0.4013 - transformer_accuracy: 2.4487e-05 - flow_accuracy: 0.4861 - val_loss: 2.3116e-04 - val_transformer_loss: 2.3116e-04 - val_flow_loss: 0.2440 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3604 - 53s/epoch - 530ms/step\n",
            "Epoch 19/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 19: val_loss improved from 0.00023 to 0.00022, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.3107e-04 - transformer_loss: 2.3107e-04 - flow_loss: 0.4113 - transformer_accuracy: 2.3462e-05 - flow_accuracy: 0.4840 - val_loss: 2.2343e-04 - val_transformer_loss: 2.2343e-04 - val_flow_loss: 0.2394 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4148 - 53s/epoch - 529ms/step\n",
            "Epoch 20/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 20: val_loss improved from 0.00022 to 0.00022, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.2656e-04 - transformer_loss: 2.2656e-04 - flow_loss: 0.4228 - transformer_accuracy: 2.4658e-05 - flow_accuracy: 0.4830 - val_loss: 2.2030e-04 - val_transformer_loss: 2.2030e-04 - val_flow_loss: 0.2514 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4456 - 53s/epoch - 529ms/step\n",
            "Epoch 21/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 21: val_loss improved from 0.00022 to 0.00022, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.2176e-04 - transformer_loss: 2.2176e-04 - flow_loss: 0.4305 - transformer_accuracy: 2.4341e-05 - flow_accuracy: 0.4808 - val_loss: 2.1794e-04 - val_transformer_loss: 2.1794e-04 - val_flow_loss: 0.2435 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3828 - 53s/epoch - 527ms/step\n",
            "Epoch 22/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 22: val_loss improved from 0.00022 to 0.00021, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.1702e-04 - transformer_loss: 2.1702e-04 - flow_loss: 0.4390 - transformer_accuracy: 2.5635e-05 - flow_accuracy: 0.4812 - val_loss: 2.1175e-04 - val_transformer_loss: 2.1175e-04 - val_flow_loss: 0.2516 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4294 - 53s/epoch - 528ms/step\n",
            "Epoch 23/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 23: val_loss improved from 0.00021 to 0.00021, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.1297e-04 - transformer_loss: 2.1297e-04 - flow_loss: 0.4452 - transformer_accuracy: 2.5659e-05 - flow_accuracy: 0.4782 - val_loss: 2.1170e-04 - val_transformer_loss: 2.1170e-04 - val_flow_loss: 0.2373 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3774 - 53s/epoch - 528ms/step\n",
            "Epoch 24/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 24: val_loss improved from 0.00021 to 0.00021, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.0968e-04 - transformer_loss: 2.0968e-04 - flow_loss: 0.4531 - transformer_accuracy: 2.4414e-05 - flow_accuracy: 0.4769 - val_loss: 2.0761e-04 - val_transformer_loss: 2.0761e-04 - val_flow_loss: 0.2678 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4255 - 53s/epoch - 526ms/step\n",
            "Epoch 25/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 25: val_loss improved from 0.00021 to 0.00020, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.0621e-04 - transformer_loss: 2.0621e-04 - flow_loss: 0.4590 - transformer_accuracy: 2.5757e-05 - flow_accuracy: 0.4737 - val_loss: 2.0433e-04 - val_transformer_loss: 2.0433e-04 - val_flow_loss: 0.2635 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4897 - 53s/epoch - 528ms/step\n",
            "Epoch 26/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 26: val_loss improved from 0.00020 to 0.00020, saving model to model.h5\n",
            "100/100 - 53s - loss: 2.0195e-04 - transformer_loss: 2.0195e-04 - flow_loss: 0.4639 - transformer_accuracy: 2.4976e-05 - flow_accuracy: 0.4774 - val_loss: 1.9547e-04 - val_transformer_loss: 1.9547e-04 - val_flow_loss: 0.2754 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4167 - 53s/epoch - 527ms/step\n",
            "Epoch 27/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 27: val_loss improved from 0.00020 to 0.00019, saving model to model.h5\n",
            "100/100 - 53s - loss: 1.9899e-04 - transformer_loss: 1.9899e-04 - flow_loss: 0.4725 - transformer_accuracy: 2.5293e-05 - flow_accuracy: 0.4707 - val_loss: 1.9382e-04 - val_transformer_loss: 1.9382e-04 - val_flow_loss: 0.2843 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4514 - 53s/epoch - 529ms/step\n",
            "Epoch 28/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.00019\n",
            "100/100 - 53s - loss: 1.9694e-04 - transformer_loss: 1.9694e-04 - flow_loss: 0.4798 - transformer_accuracy: 2.4170e-05 - flow_accuracy: 0.4701 - val_loss: 1.9707e-04 - val_transformer_loss: 1.9707e-04 - val_flow_loss: 0.2793 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4241 - 53s/epoch - 526ms/step\n",
            "Epoch 29/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 29: val_loss improved from 0.00019 to 0.00019, saving model to model.h5\n",
            "100/100 - 53s - loss: 1.9469e-04 - transformer_loss: 1.9469e-04 - flow_loss: 0.4890 - transformer_accuracy: 2.5122e-05 - flow_accuracy: 0.4707 - val_loss: 1.9050e-04 - val_transformer_loss: 1.9050e-04 - val_flow_loss: 0.2673 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4221 - 53s/epoch - 529ms/step\n",
            "Epoch 30/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.00019\n",
            "100/100 - 53s - loss: 1.9083e-04 - transformer_loss: 1.9083e-04 - flow_loss: 0.4887 - transformer_accuracy: 2.3413e-05 - flow_accuracy: 0.4711 - val_loss: 1.9239e-04 - val_transformer_loss: 1.9239e-04 - val_flow_loss: 0.2907 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3972 - 53s/epoch - 528ms/step\n",
            "Epoch 31/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.00019\n",
            "100/100 - 52s - loss: 1.8832e-04 - transformer_loss: 1.8832e-04 - flow_loss: 0.4948 - transformer_accuracy: 2.5024e-05 - flow_accuracy: 0.4660 - val_loss: 1.9240e-04 - val_transformer_loss: 1.9240e-04 - val_flow_loss: 0.2851 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3718 - 52s/epoch - 525ms/step\n",
            "Epoch 32/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 32: val_loss improved from 0.00019 to 0.00019, saving model to model.h5\n",
            "100/100 - 53s - loss: 1.8682e-04 - transformer_loss: 1.8682e-04 - flow_loss: 0.5008 - transformer_accuracy: 2.3022e-05 - flow_accuracy: 0.4649 - val_loss: 1.8825e-04 - val_transformer_loss: 1.8825e-04 - val_flow_loss: 0.2962 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3870 - 53s/epoch - 526ms/step\n",
            "Epoch 33/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.00019\n",
            "100/100 - 53s - loss: 1.8398e-04 - transformer_loss: 1.8398e-04 - flow_loss: 0.5070 - transformer_accuracy: 2.5537e-05 - flow_accuracy: 0.4665 - val_loss: 1.8902e-04 - val_transformer_loss: 1.8902e-04 - val_flow_loss: 0.2987 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4304 - 53s/epoch - 526ms/step\n",
            "Epoch 34/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 34: val_loss improved from 0.00019 to 0.00018, saving model to model.h5\n",
            "100/100 - 53s - loss: 1.8209e-04 - transformer_loss: 1.8209e-04 - flow_loss: 0.5130 - transformer_accuracy: 2.4561e-05 - flow_accuracy: 0.4657 - val_loss: 1.8452e-04 - val_transformer_loss: 1.8452e-04 - val_flow_loss: 0.2997 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3738 - 53s/epoch - 525ms/step\n",
            "Epoch 35/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 35: val_loss improved from 0.00018 to 0.00018, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.7907e-04 - transformer_loss: 1.7907e-04 - flow_loss: 0.5172 - transformer_accuracy: 2.6904e-05 - flow_accuracy: 0.4638 - val_loss: 1.8106e-04 - val_transformer_loss: 1.8106e-04 - val_flow_loss: 0.2875 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3665 - 52s/epoch - 523ms/step\n",
            "Epoch 36/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.00018\n",
            "100/100 - 52s - loss: 1.7727e-04 - transformer_loss: 1.7727e-04 - flow_loss: 0.5202 - transformer_accuracy: 2.4292e-05 - flow_accuracy: 0.4608 - val_loss: 1.8423e-04 - val_transformer_loss: 1.8423e-04 - val_flow_loss: 0.2981 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3962 - 52s/epoch - 523ms/step\n",
            "Epoch 37/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 37: val_loss improved from 0.00018 to 0.00018, saving model to model.h5\n",
            "100/100 - 53s - loss: 1.7505e-04 - transformer_loss: 1.7505e-04 - flow_loss: 0.5268 - transformer_accuracy: 2.3730e-05 - flow_accuracy: 0.4607 - val_loss: 1.7777e-04 - val_transformer_loss: 1.7777e-04 - val_flow_loss: 0.2986 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3867 - 53s/epoch - 526ms/step\n",
            "Epoch 38/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.00018\n",
            "100/100 - 53s - loss: 1.7270e-04 - transformer_loss: 1.7270e-04 - flow_loss: 0.5322 - transformer_accuracy: 2.6318e-05 - flow_accuracy: 0.4624 - val_loss: 1.8459e-04 - val_transformer_loss: 1.8459e-04 - val_flow_loss: 0.2892 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4402 - 53s/epoch - 527ms/step\n",
            "Epoch 39/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.00018\n",
            "100/100 - 53s - loss: 1.7286e-04 - transformer_loss: 1.7286e-04 - flow_loss: 0.5353 - transformer_accuracy: 2.4341e-05 - flow_accuracy: 0.4594 - val_loss: 1.8026e-04 - val_transformer_loss: 1.8026e-04 - val_flow_loss: 0.3115 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4192 - 53s/epoch - 526ms/step\n",
            "Epoch 40/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 40: val_loss improved from 0.00018 to 0.00018, saving model to model.h5\n",
            "100/100 - 53s - loss: 1.6838e-04 - transformer_loss: 1.6838e-04 - flow_loss: 0.5389 - transformer_accuracy: 2.4268e-05 - flow_accuracy: 0.4597 - val_loss: 1.7694e-04 - val_transformer_loss: 1.7694e-04 - val_flow_loss: 0.3123 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3877 - 53s/epoch - 529ms/step\n",
            "Epoch 41/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 41: val_loss improved from 0.00018 to 0.00018, saving model to model.h5\n",
            "100/100 - 53s - loss: 1.6753e-04 - transformer_loss: 1.6753e-04 - flow_loss: 0.5453 - transformer_accuracy: 2.3853e-05 - flow_accuracy: 0.4609 - val_loss: 1.7577e-04 - val_transformer_loss: 1.7577e-04 - val_flow_loss: 0.3128 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4131 - 53s/epoch - 527ms/step\n",
            "Epoch 42/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.00018\n",
            "100/100 - 52s - loss: 1.6585e-04 - transformer_loss: 1.6585e-04 - flow_loss: 0.5466 - transformer_accuracy: 2.5684e-05 - flow_accuracy: 0.4586 - val_loss: 1.7645e-04 - val_transformer_loss: 1.7645e-04 - val_flow_loss: 0.3110 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4504 - 52s/epoch - 518ms/step\n",
            "Epoch 43/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 43: val_loss improved from 0.00018 to 0.00017, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.6414e-04 - transformer_loss: 1.6414e-04 - flow_loss: 0.5525 - transformer_accuracy: 2.3022e-05 - flow_accuracy: 0.4587 - val_loss: 1.7179e-04 - val_transformer_loss: 1.7179e-04 - val_flow_loss: 0.3198 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4409 - 52s/epoch - 516ms/step\n",
            "Epoch 44/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 44: val_loss improved from 0.00017 to 0.00017, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.6255e-04 - transformer_loss: 1.6255e-04 - flow_loss: 0.5560 - transformer_accuracy: 2.4707e-05 - flow_accuracy: 0.4574 - val_loss: 1.6941e-04 - val_transformer_loss: 1.6941e-04 - val_flow_loss: 0.3277 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4253 - 51s/epoch - 515ms/step\n",
            "Epoch 45/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 45: val_loss improved from 0.00017 to 0.00017, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.6159e-04 - transformer_loss: 1.6159e-04 - flow_loss: 0.5588 - transformer_accuracy: 2.4512e-05 - flow_accuracy: 0.4566 - val_loss: 1.6823e-04 - val_transformer_loss: 1.6823e-04 - val_flow_loss: 0.3208 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3657 - 51s/epoch - 512ms/step\n",
            "Epoch 46/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 46: val_loss improved from 0.00017 to 0.00016, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.5900e-04 - transformer_loss: 1.5900e-04 - flow_loss: 0.5627 - transformer_accuracy: 2.3877e-05 - flow_accuracy: 0.4542 - val_loss: 1.6356e-04 - val_transformer_loss: 1.6356e-04 - val_flow_loss: 0.3466 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4114 - 52s/epoch - 516ms/step\n",
            "Epoch 47/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.00016\n",
            "100/100 - 51s - loss: 1.5841e-04 - transformer_loss: 1.5841e-04 - flow_loss: 0.5688 - transformer_accuracy: 2.4341e-05 - flow_accuracy: 0.4580 - val_loss: 1.6485e-04 - val_transformer_loss: 1.6485e-04 - val_flow_loss: 0.3414 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3987 - 51s/epoch - 511ms/step\n",
            "Epoch 48/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.00016\n",
            "100/100 - 51s - loss: 1.5717e-04 - transformer_loss: 1.5717e-04 - flow_loss: 0.5710 - transformer_accuracy: 2.4072e-05 - flow_accuracy: 0.4561 - val_loss: 1.6604e-04 - val_transformer_loss: 1.6604e-04 - val_flow_loss: 0.3381 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3943 - 51s/epoch - 513ms/step\n",
            "Epoch 49/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.00016\n",
            "100/100 - 51s - loss: 1.5666e-04 - transformer_loss: 1.5666e-04 - flow_loss: 0.5741 - transformer_accuracy: 2.4731e-05 - flow_accuracy: 0.4567 - val_loss: 1.6509e-04 - val_transformer_loss: 1.6509e-04 - val_flow_loss: 0.3320 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3740 - 51s/epoch - 514ms/step\n",
            "Epoch 50/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 50: val_loss improved from 0.00016 to 0.00016, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.5380e-04 - transformer_loss: 1.5380e-04 - flow_loss: 0.5771 - transformer_accuracy: 2.3120e-05 - flow_accuracy: 0.4541 - val_loss: 1.6347e-04 - val_transformer_loss: 1.6347e-04 - val_flow_loss: 0.3391 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3899 - 52s/epoch - 517ms/step\n",
            "Epoch 51/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 51: val_loss improved from 0.00016 to 0.00016, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.5276e-04 - transformer_loss: 1.5276e-04 - flow_loss: 0.5794 - transformer_accuracy: 2.5000e-05 - flow_accuracy: 0.4548 - val_loss: 1.5977e-04 - val_transformer_loss: 1.5977e-04 - val_flow_loss: 0.3486 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3970 - 52s/epoch - 517ms/step\n",
            "Epoch 52/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.00016\n",
            "100/100 - 52s - loss: 1.5227e-04 - transformer_loss: 1.5227e-04 - flow_loss: 0.5845 - transformer_accuracy: 2.6147e-05 - flow_accuracy: 0.4532 - val_loss: 1.6158e-04 - val_transformer_loss: 1.6158e-04 - val_flow_loss: 0.3573 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4395 - 52s/epoch - 517ms/step\n",
            "Epoch 53/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 53: val_loss improved from 0.00016 to 0.00016, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.5081e-04 - transformer_loss: 1.5081e-04 - flow_loss: 0.5852 - transformer_accuracy: 2.3682e-05 - flow_accuracy: 0.4559 - val_loss: 1.5750e-04 - val_transformer_loss: 1.5750e-04 - val_flow_loss: 0.3475 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4031 - 52s/epoch - 520ms/step\n",
            "Epoch 54/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.00016\n",
            "100/100 - 52s - loss: 1.5006e-04 - transformer_loss: 1.5006e-04 - flow_loss: 0.5880 - transformer_accuracy: 2.5220e-05 - flow_accuracy: 0.4518 - val_loss: 1.5981e-04 - val_transformer_loss: 1.5981e-04 - val_flow_loss: 0.3558 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4194 - 52s/epoch - 516ms/step\n",
            "Epoch 55/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 55: val_loss improved from 0.00016 to 0.00016, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.4766e-04 - transformer_loss: 1.4766e-04 - flow_loss: 0.5920 - transformer_accuracy: 2.4780e-05 - flow_accuracy: 0.4523 - val_loss: 1.5667e-04 - val_transformer_loss: 1.5667e-04 - val_flow_loss: 0.3635 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3872 - 51s/epoch - 513ms/step\n",
            "Epoch 56/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 56: val_loss improved from 0.00016 to 0.00015, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.4825e-04 - transformer_loss: 1.4825e-04 - flow_loss: 0.5961 - transformer_accuracy: 2.5146e-05 - flow_accuracy: 0.4555 - val_loss: 1.5322e-04 - val_transformer_loss: 1.5322e-04 - val_flow_loss: 0.3622 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4014 - 51s/epoch - 514ms/step\n",
            "Epoch 57/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.00015\n",
            "100/100 - 52s - loss: 1.4643e-04 - transformer_loss: 1.4643e-04 - flow_loss: 0.5961 - transformer_accuracy: 2.4023e-05 - flow_accuracy: 0.4520 - val_loss: 1.5854e-04 - val_transformer_loss: 1.5854e-04 - val_flow_loss: 0.3555 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3679 - 52s/epoch - 516ms/step\n",
            "Epoch 58/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.00015\n",
            "100/100 - 52s - loss: 1.4524e-04 - transformer_loss: 1.4524e-04 - flow_loss: 0.5979 - transformer_accuracy: 2.5513e-05 - flow_accuracy: 0.4516 - val_loss: 1.5366e-04 - val_transformer_loss: 1.5366e-04 - val_flow_loss: 0.3525 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3247 - 52s/epoch - 516ms/step\n",
            "Epoch 59/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 59: val_loss improved from 0.00015 to 0.00015, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.4416e-04 - transformer_loss: 1.4416e-04 - flow_loss: 0.5991 - transformer_accuracy: 2.4341e-05 - flow_accuracy: 0.4534 - val_loss: 1.5112e-04 - val_transformer_loss: 1.5112e-04 - val_flow_loss: 0.3502 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3716 - 51s/epoch - 512ms/step\n",
            "Epoch 60/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 60: val_loss did not improve from 0.00015\n",
            "100/100 - 52s - loss: 1.4343e-04 - transformer_loss: 1.4343e-04 - flow_loss: 0.6037 - transformer_accuracy: 2.5635e-05 - flow_accuracy: 0.4518 - val_loss: 1.5352e-04 - val_transformer_loss: 1.5352e-04 - val_flow_loss: 0.3569 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3875 - 52s/epoch - 517ms/step\n",
            "Epoch 61/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 61: val_loss improved from 0.00015 to 0.00015, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.4214e-04 - transformer_loss: 1.4214e-04 - flow_loss: 0.6050 - transformer_accuracy: 2.4658e-05 - flow_accuracy: 0.4521 - val_loss: 1.5031e-04 - val_transformer_loss: 1.5031e-04 - val_flow_loss: 0.3532 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4314 - 52s/epoch - 516ms/step\n",
            "Epoch 62/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 62: val_loss improved from 0.00015 to 0.00015, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.4186e-04 - transformer_loss: 1.4186e-04 - flow_loss: 0.6093 - transformer_accuracy: 2.5220e-05 - flow_accuracy: 0.4531 - val_loss: 1.4901e-04 - val_transformer_loss: 1.4901e-04 - val_flow_loss: 0.3720 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3855 - 52s/epoch - 516ms/step\n",
            "Epoch 63/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 63: val_loss improved from 0.00015 to 0.00015, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.4078e-04 - transformer_loss: 1.4078e-04 - flow_loss: 0.6095 - transformer_accuracy: 2.4683e-05 - flow_accuracy: 0.4520 - val_loss: 1.4873e-04 - val_transformer_loss: 1.4873e-04 - val_flow_loss: 0.3695 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3699 - 52s/epoch - 518ms/step\n",
            "Epoch 64/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 64: val_loss did not improve from 0.00015\n",
            "100/100 - 52s - loss: 1.4026e-04 - transformer_loss: 1.4026e-04 - flow_loss: 0.6102 - transformer_accuracy: 2.2778e-05 - flow_accuracy: 0.4510 - val_loss: 1.5120e-04 - val_transformer_loss: 1.5120e-04 - val_flow_loss: 0.3896 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4172 - 52s/epoch - 516ms/step\n",
            "Epoch 65/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 65: val_loss improved from 0.00015 to 0.00015, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.3842e-04 - transformer_loss: 1.3842e-04 - flow_loss: 0.6145 - transformer_accuracy: 2.4780e-05 - flow_accuracy: 0.4512 - val_loss: 1.4834e-04 - val_transformer_loss: 1.4834e-04 - val_flow_loss: 0.3740 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3794 - 52s/epoch - 517ms/step\n",
            "Epoch 66/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 66: val_loss improved from 0.00015 to 0.00015, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.3799e-04 - transformer_loss: 1.3799e-04 - flow_loss: 0.6159 - transformer_accuracy: 2.4048e-05 - flow_accuracy: 0.4526 - val_loss: 1.4757e-04 - val_transformer_loss: 1.4757e-04 - val_flow_loss: 0.3650 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3818 - 52s/epoch - 516ms/step\n",
            "Epoch 67/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.3763e-04 - transformer_loss: 1.3763e-04 - flow_loss: 0.6184 - transformer_accuracy: 2.4658e-05 - flow_accuracy: 0.4522 - val_loss: 1.5091e-04 - val_transformer_loss: 1.5091e-04 - val_flow_loss: 0.3892 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3972 - 51s/epoch - 510ms/step\n",
            "Epoch 68/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.3623e-04 - transformer_loss: 1.3623e-04 - flow_loss: 0.6210 - transformer_accuracy: 2.5073e-05 - flow_accuracy: 0.4530 - val_loss: 1.4843e-04 - val_transformer_loss: 1.4843e-04 - val_flow_loss: 0.3750 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4016 - 51s/epoch - 509ms/step\n",
            "Epoch 69/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.3588e-04 - transformer_loss: 1.3588e-04 - flow_loss: 0.6240 - transformer_accuracy: 2.4268e-05 - flow_accuracy: 0.4522 - val_loss: 1.4977e-04 - val_transformer_loss: 1.4977e-04 - val_flow_loss: 0.3791 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3777 - 51s/epoch - 513ms/step\n",
            "Epoch 70/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.3500e-04 - transformer_loss: 1.3500e-04 - flow_loss: 0.6237 - transformer_accuracy: 2.4438e-05 - flow_accuracy: 0.4492 - val_loss: 1.5063e-04 - val_transformer_loss: 1.5063e-04 - val_flow_loss: 0.3703 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3662 - 51s/epoch - 513ms/step\n",
            "Epoch 71/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 71: val_loss improved from 0.00015 to 0.00015, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.3557e-04 - transformer_loss: 1.3557e-04 - flow_loss: 0.6285 - transformer_accuracy: 2.5415e-05 - flow_accuracy: 0.4517 - val_loss: 1.4704e-04 - val_transformer_loss: 1.4704e-04 - val_flow_loss: 0.3803 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4285 - 51s/epoch - 512ms/step\n",
            "Epoch 72/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.3309e-04 - transformer_loss: 1.3309e-04 - flow_loss: 0.6277 - transformer_accuracy: 2.4829e-05 - flow_accuracy: 0.4506 - val_loss: 1.5125e-04 - val_transformer_loss: 1.5125e-04 - val_flow_loss: 0.3819 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4463 - 51s/epoch - 510ms/step\n",
            "Epoch 73/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.3294e-04 - transformer_loss: 1.3294e-04 - flow_loss: 0.6297 - transformer_accuracy: 2.4365e-05 - flow_accuracy: 0.4507 - val_loss: 1.5593e-04 - val_transformer_loss: 1.5593e-04 - val_flow_loss: 0.3812 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3994 - 51s/epoch - 511ms/step\n",
            "Epoch 74/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 74: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.3277e-04 - transformer_loss: 1.3277e-04 - flow_loss: 0.6341 - transformer_accuracy: 2.3608e-05 - flow_accuracy: 0.4515 - val_loss: 1.5373e-04 - val_transformer_loss: 1.5373e-04 - val_flow_loss: 0.3706 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3811 - 51s/epoch - 510ms/step\n",
            "Epoch 75/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 75: val_loss improved from 0.00015 to 0.00015, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.3098e-04 - transformer_loss: 1.3098e-04 - flow_loss: 0.6319 - transformer_accuracy: 2.4731e-05 - flow_accuracy: 0.4499 - val_loss: 1.4701e-04 - val_transformer_loss: 1.4701e-04 - val_flow_loss: 0.3868 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4033 - 51s/epoch - 513ms/step\n",
            "Epoch 76/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 76: val_loss improved from 0.00015 to 0.00015, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.3023e-04 - transformer_loss: 1.3023e-04 - flow_loss: 0.6337 - transformer_accuracy: 2.4365e-05 - flow_accuracy: 0.4494 - val_loss: 1.4530e-04 - val_transformer_loss: 1.4530e-04 - val_flow_loss: 0.4009 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3555 - 51s/epoch - 514ms/step\n",
            "Epoch 77/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.3044e-04 - transformer_loss: 1.3044e-04 - flow_loss: 0.6365 - transformer_accuracy: 2.3730e-05 - flow_accuracy: 0.4495 - val_loss: 1.5041e-04 - val_transformer_loss: 1.5041e-04 - val_flow_loss: 0.3870 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4446 - 51s/epoch - 512ms/step\n",
            "Epoch 78/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 78: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.3000e-04 - transformer_loss: 1.3000e-04 - flow_loss: 0.6388 - transformer_accuracy: 2.3267e-05 - flow_accuracy: 0.4499 - val_loss: 1.4653e-04 - val_transformer_loss: 1.4653e-04 - val_flow_loss: 0.4046 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4155 - 51s/epoch - 515ms/step\n",
            "Epoch 79/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.2824e-04 - transformer_loss: 1.2824e-04 - flow_loss: 0.6392 - transformer_accuracy: 2.4487e-05 - flow_accuracy: 0.4485 - val_loss: 1.4656e-04 - val_transformer_loss: 1.4656e-04 - val_flow_loss: 0.4028 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3916 - 51s/epoch - 512ms/step\n",
            "Epoch 80/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.2852e-04 - transformer_loss: 1.2852e-04 - flow_loss: 0.6433 - transformer_accuracy: 2.3901e-05 - flow_accuracy: 0.4507 - val_loss: 1.5521e-04 - val_transformer_loss: 1.5521e-04 - val_flow_loss: 0.4040 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4102 - 51s/epoch - 512ms/step\n",
            "Epoch 81/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.00015\n",
            "100/100 - 52s - loss: 1.2786e-04 - transformer_loss: 1.2786e-04 - flow_loss: 0.6450 - transformer_accuracy: 2.6245e-05 - flow_accuracy: 0.4495 - val_loss: 1.4885e-04 - val_transformer_loss: 1.4885e-04 - val_flow_loss: 0.3945 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4111 - 52s/epoch - 516ms/step\n",
            "Epoch 82/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.00015\n",
            "100/100 - 52s - loss: 1.2710e-04 - transformer_loss: 1.2710e-04 - flow_loss: 0.6475 - transformer_accuracy: 2.3242e-05 - flow_accuracy: 0.4509 - val_loss: 1.4719e-04 - val_transformer_loss: 1.4719e-04 - val_flow_loss: 0.3871 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3835 - 52s/epoch - 515ms/step\n",
            "Epoch 83/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.00015\n",
            "100/100 - 51s - loss: 1.2617e-04 - transformer_loss: 1.2617e-04 - flow_loss: 0.6494 - transformer_accuracy: 2.2876e-05 - flow_accuracy: 0.4524 - val_loss: 1.4603e-04 - val_transformer_loss: 1.4603e-04 - val_flow_loss: 0.3891 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4473 - 51s/epoch - 513ms/step\n",
            "Epoch 84/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 84: val_loss did not improve from 0.00015\n",
            "100/100 - 52s - loss: 1.2595e-04 - transformer_loss: 1.2595e-04 - flow_loss: 0.6474 - transformer_accuracy: 2.5586e-05 - flow_accuracy: 0.4517 - val_loss: 1.4676e-04 - val_transformer_loss: 1.4676e-04 - val_flow_loss: 0.3826 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3184 - 52s/epoch - 515ms/step\n",
            "Epoch 85/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 85: val_loss improved from 0.00015 to 0.00014, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.2577e-04 - transformer_loss: 1.2577e-04 - flow_loss: 0.6514 - transformer_accuracy: 2.5195e-05 - flow_accuracy: 0.4493 - val_loss: 1.4454e-04 - val_transformer_loss: 1.4454e-04 - val_flow_loss: 0.4061 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4124 - 51s/epoch - 512ms/step\n",
            "Epoch 86/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 86: val_loss improved from 0.00014 to 0.00014, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.2476e-04 - transformer_loss: 1.2476e-04 - flow_loss: 0.6518 - transformer_accuracy: 2.4512e-05 - flow_accuracy: 0.4475 - val_loss: 1.4453e-04 - val_transformer_loss: 1.4453e-04 - val_flow_loss: 0.3940 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3521 - 52s/epoch - 515ms/step\n",
            "Epoch 87/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 87: val_loss improved from 0.00014 to 0.00014, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.2482e-04 - transformer_loss: 1.2482e-04 - flow_loss: 0.6524 - transformer_accuracy: 2.5781e-05 - flow_accuracy: 0.4495 - val_loss: 1.4332e-04 - val_transformer_loss: 1.4332e-04 - val_flow_loss: 0.3878 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4597 - 51s/epoch - 515ms/step\n",
            "Epoch 88/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 88: val_loss improved from 0.00014 to 0.00014, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.2503e-04 - transformer_loss: 1.2503e-04 - flow_loss: 0.6533 - transformer_accuracy: 2.4121e-05 - flow_accuracy: 0.4480 - val_loss: 1.4161e-04 - val_transformer_loss: 1.4161e-04 - val_flow_loss: 0.3944 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4033 - 51s/epoch - 513ms/step\n",
            "Epoch 89/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 89: val_loss improved from 0.00014 to 0.00014, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.2361e-04 - transformer_loss: 1.2361e-04 - flow_loss: 0.6531 - transformer_accuracy: 2.4829e-05 - flow_accuracy: 0.4487 - val_loss: 1.3698e-04 - val_transformer_loss: 1.3698e-04 - val_flow_loss: 0.3922 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4089 - 52s/epoch - 517ms/step\n",
            "Epoch 90/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.2330e-04 - transformer_loss: 1.2330e-04 - flow_loss: 0.6565 - transformer_accuracy: 2.4561e-05 - flow_accuracy: 0.4488 - val_loss: 1.3895e-04 - val_transformer_loss: 1.3895e-04 - val_flow_loss: 0.4111 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4414 - 52s/epoch - 515ms/step\n",
            "Epoch 91/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.00014\n",
            "100/100 - 51s - loss: 1.2292e-04 - transformer_loss: 1.2292e-04 - flow_loss: 0.6615 - transformer_accuracy: 2.4829e-05 - flow_accuracy: 0.4499 - val_loss: 1.4054e-04 - val_transformer_loss: 1.4054e-04 - val_flow_loss: 0.4004 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4243 - 51s/epoch - 514ms/step\n",
            "Epoch 92/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.00014\n",
            "100/100 - 51s - loss: 1.2235e-04 - transformer_loss: 1.2235e-04 - flow_loss: 0.6573 - transformer_accuracy: 2.3047e-05 - flow_accuracy: 0.4493 - val_loss: 1.4120e-04 - val_transformer_loss: 1.4120e-04 - val_flow_loss: 0.4013 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3699 - 51s/epoch - 513ms/step\n",
            "Epoch 93/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.2181e-04 - transformer_loss: 1.2181e-04 - flow_loss: 0.6641 - transformer_accuracy: 2.3755e-05 - flow_accuracy: 0.4494 - val_loss: 1.4296e-04 - val_transformer_loss: 1.4296e-04 - val_flow_loss: 0.3865 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4260 - 52s/epoch - 516ms/step\n",
            "Epoch 94/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.2129e-04 - transformer_loss: 1.2129e-04 - flow_loss: 0.6643 - transformer_accuracy: 2.3486e-05 - flow_accuracy: 0.4487 - val_loss: 1.3980e-04 - val_transformer_loss: 1.3980e-04 - val_flow_loss: 0.3907 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3928 - 52s/epoch - 516ms/step\n",
            "Epoch 95/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.2139e-04 - transformer_loss: 1.2139e-04 - flow_loss: 0.6656 - transformer_accuracy: 2.4268e-05 - flow_accuracy: 0.4487 - val_loss: 1.4005e-04 - val_transformer_loss: 1.4005e-04 - val_flow_loss: 0.4037 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4045 - 52s/epoch - 523ms/step\n",
            "Epoch 96/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.2132e-04 - transformer_loss: 1.2132e-04 - flow_loss: 0.6661 - transformer_accuracy: 2.3950e-05 - flow_accuracy: 0.4489 - val_loss: 1.4297e-04 - val_transformer_loss: 1.4297e-04 - val_flow_loss: 0.3658 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4465 - 52s/epoch - 515ms/step\n",
            "Epoch 97/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.2038e-04 - transformer_loss: 1.2038e-04 - flow_loss: 0.6638 - transformer_accuracy: 2.3535e-05 - flow_accuracy: 0.4497 - val_loss: 1.4211e-04 - val_transformer_loss: 1.4211e-04 - val_flow_loss: 0.4023 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3689 - 52s/epoch - 518ms/step\n",
            "Epoch 98/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1873e-04 - transformer_loss: 1.1873e-04 - flow_loss: 0.6671 - transformer_accuracy: 2.4463e-05 - flow_accuracy: 0.4477 - val_loss: 1.3758e-04 - val_transformer_loss: 1.3758e-04 - val_flow_loss: 0.3904 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4019 - 52s/epoch - 521ms/step\n",
            "Epoch 99/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 99: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1933e-04 - transformer_loss: 1.1933e-04 - flow_loss: 0.6694 - transformer_accuracy: 2.4634e-05 - flow_accuracy: 0.4499 - val_loss: 1.3743e-04 - val_transformer_loss: 1.3743e-04 - val_flow_loss: 0.4120 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4041 - 52s/epoch - 521ms/step\n",
            "Epoch 100/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1837e-04 - transformer_loss: 1.1837e-04 - flow_loss: 0.6712 - transformer_accuracy: 2.5049e-05 - flow_accuracy: 0.4466 - val_loss: 1.3908e-04 - val_transformer_loss: 1.3908e-04 - val_flow_loss: 0.4128 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3584 - 52s/epoch - 519ms/step\n",
            "Epoch 101/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1844e-04 - transformer_loss: 1.1844e-04 - flow_loss: 0.6728 - transformer_accuracy: 2.4829e-05 - flow_accuracy: 0.4475 - val_loss: 1.3707e-04 - val_transformer_loss: 1.3707e-04 - val_flow_loss: 0.3949 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3865 - 52s/epoch - 523ms/step\n",
            "Epoch 102/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1795e-04 - transformer_loss: 1.1795e-04 - flow_loss: 0.6722 - transformer_accuracy: 2.5464e-05 - flow_accuracy: 0.4485 - val_loss: 1.3737e-04 - val_transformer_loss: 1.3737e-04 - val_flow_loss: 0.4232 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3896 - 52s/epoch - 520ms/step\n",
            "Epoch 103/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1742e-04 - transformer_loss: 1.1742e-04 - flow_loss: 0.6751 - transformer_accuracy: 2.5977e-05 - flow_accuracy: 0.4478 - val_loss: 1.4233e-04 - val_transformer_loss: 1.4233e-04 - val_flow_loss: 0.4249 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4067 - 52s/epoch - 520ms/step\n",
            "Epoch 104/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1686e-04 - transformer_loss: 1.1686e-04 - flow_loss: 0.6742 - transformer_accuracy: 2.4048e-05 - flow_accuracy: 0.4476 - val_loss: 1.4308e-04 - val_transformer_loss: 1.4308e-04 - val_flow_loss: 0.4221 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4373 - 52s/epoch - 518ms/step\n",
            "Epoch 105/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1769e-04 - transformer_loss: 1.1769e-04 - flow_loss: 0.6764 - transformer_accuracy: 2.4219e-05 - flow_accuracy: 0.4492 - val_loss: 1.4376e-04 - val_transformer_loss: 1.4376e-04 - val_flow_loss: 0.3766 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3425 - 52s/epoch - 521ms/step\n",
            "Epoch 106/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 106: val_loss improved from 0.00014 to 0.00014, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.1659e-04 - transformer_loss: 1.1659e-04 - flow_loss: 0.6779 - transformer_accuracy: 2.4463e-05 - flow_accuracy: 0.4476 - val_loss: 1.3678e-04 - val_transformer_loss: 1.3678e-04 - val_flow_loss: 0.4058 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3767 - 52s/epoch - 521ms/step\n",
            "Epoch 107/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1527e-04 - transformer_loss: 1.1527e-04 - flow_loss: 0.6763 - transformer_accuracy: 2.4878e-05 - flow_accuracy: 0.4470 - val_loss: 1.4088e-04 - val_transformer_loss: 1.4088e-04 - val_flow_loss: 0.4683 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3630 - 52s/epoch - 520ms/step\n",
            "Epoch 108/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1601e-04 - transformer_loss: 1.1601e-04 - flow_loss: 0.6791 - transformer_accuracy: 2.3071e-05 - flow_accuracy: 0.4496 - val_loss: 1.3802e-04 - val_transformer_loss: 1.3802e-04 - val_flow_loss: 0.4116 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3833 - 52s/epoch - 517ms/step\n",
            "Epoch 109/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 109: val_loss did not improve from 0.00014\n",
            "100/100 - 51s - loss: 1.1590e-04 - transformer_loss: 1.1590e-04 - flow_loss: 0.6828 - transformer_accuracy: 2.4927e-05 - flow_accuracy: 0.4484 - val_loss: 1.3843e-04 - val_transformer_loss: 1.3843e-04 - val_flow_loss: 0.3911 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3774 - 51s/epoch - 512ms/step\n",
            "Epoch 110/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 110: val_loss improved from 0.00014 to 0.00014, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.1472e-04 - transformer_loss: 1.1472e-04 - flow_loss: 0.6785 - transformer_accuracy: 2.3730e-05 - flow_accuracy: 0.4469 - val_loss: 1.3538e-04 - val_transformer_loss: 1.3538e-04 - val_flow_loss: 0.4245 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4067 - 52s/epoch - 517ms/step\n",
            "Epoch 111/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.00014\n",
            "100/100 - 51s - loss: 1.1368e-04 - transformer_loss: 1.1368e-04 - flow_loss: 0.6806 - transformer_accuracy: 2.3853e-05 - flow_accuracy: 0.4492 - val_loss: 1.3905e-04 - val_transformer_loss: 1.3905e-04 - val_flow_loss: 0.3961 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3584 - 51s/epoch - 514ms/step\n",
            "Epoch 112/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1405e-04 - transformer_loss: 1.1405e-04 - flow_loss: 0.6842 - transformer_accuracy: 2.4268e-05 - flow_accuracy: 0.4464 - val_loss: 1.4725e-04 - val_transformer_loss: 1.4725e-04 - val_flow_loss: 0.4152 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4033 - 52s/epoch - 517ms/step\n",
            "Epoch 113/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1443e-04 - transformer_loss: 1.1443e-04 - flow_loss: 0.6852 - transformer_accuracy: 2.3535e-05 - flow_accuracy: 0.4479 - val_loss: 1.4051e-04 - val_transformer_loss: 1.4051e-04 - val_flow_loss: 0.4046 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4248 - 52s/epoch - 515ms/step\n",
            "Epoch 114/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 114: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1340e-04 - transformer_loss: 1.1340e-04 - flow_loss: 0.6832 - transformer_accuracy: 2.5024e-05 - flow_accuracy: 0.4464 - val_loss: 1.3849e-04 - val_transformer_loss: 1.3849e-04 - val_flow_loss: 0.3916 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3721 - 52s/epoch - 521ms/step\n",
            "Epoch 115/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.00014\n",
            "100/100 - 51s - loss: 1.1333e-04 - transformer_loss: 1.1333e-04 - flow_loss: 0.6853 - transformer_accuracy: 2.6001e-05 - flow_accuracy: 0.4447 - val_loss: 1.4049e-04 - val_transformer_loss: 1.4049e-04 - val_flow_loss: 0.4229 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4126 - 51s/epoch - 513ms/step\n",
            "Epoch 116/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.00014\n",
            "100/100 - 51s - loss: 1.1339e-04 - transformer_loss: 1.1339e-04 - flow_loss: 0.6842 - transformer_accuracy: 2.4487e-05 - flow_accuracy: 0.4468 - val_loss: 1.4744e-04 - val_transformer_loss: 1.4744e-04 - val_flow_loss: 0.4255 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3884 - 51s/epoch - 514ms/step\n",
            "Epoch 117/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.00014\n",
            "100/100 - 52s - loss: 1.1198e-04 - transformer_loss: 1.1198e-04 - flow_loss: 0.6874 - transformer_accuracy: 2.3633e-05 - flow_accuracy: 0.4475 - val_loss: 1.4300e-04 - val_transformer_loss: 1.4300e-04 - val_flow_loss: 0.4122 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4146 - 52s/epoch - 517ms/step\n",
            "Epoch 118/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 118: val_loss improved from 0.00014 to 0.00013, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.1288e-04 - transformer_loss: 1.1288e-04 - flow_loss: 0.6885 - transformer_accuracy: 2.4219e-05 - flow_accuracy: 0.4478 - val_loss: 1.3442e-04 - val_transformer_loss: 1.3442e-04 - val_flow_loss: 0.4257 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4124 - 51s/epoch - 512ms/step\n",
            "Epoch 119/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.1218e-04 - transformer_loss: 1.1218e-04 - flow_loss: 0.6893 - transformer_accuracy: 2.4829e-05 - flow_accuracy: 0.4472 - val_loss: 1.3983e-04 - val_transformer_loss: 1.3983e-04 - val_flow_loss: 0.4320 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3638 - 52s/epoch - 516ms/step\n",
            "Epoch 120/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.1214e-04 - transformer_loss: 1.1214e-04 - flow_loss: 0.6903 - transformer_accuracy: 2.4658e-05 - flow_accuracy: 0.4472 - val_loss: 1.4077e-04 - val_transformer_loss: 1.4077e-04 - val_flow_loss: 0.4064 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3738 - 51s/epoch - 513ms/step\n",
            "Epoch 121/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.1175e-04 - transformer_loss: 1.1175e-04 - flow_loss: 0.6907 - transformer_accuracy: 2.4658e-05 - flow_accuracy: 0.4477 - val_loss: 1.4176e-04 - val_transformer_loss: 1.4176e-04 - val_flow_loss: 0.4258 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3953 - 51s/epoch - 515ms/step\n",
            "Epoch 122/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.1120e-04 - transformer_loss: 1.1120e-04 - flow_loss: 0.6889 - transformer_accuracy: 2.3999e-05 - flow_accuracy: 0.4493 - val_loss: 1.3982e-04 - val_transformer_loss: 1.3982e-04 - val_flow_loss: 0.4279 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3843 - 51s/epoch - 515ms/step\n",
            "Epoch 123/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 123: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.1079e-04 - transformer_loss: 1.1079e-04 - flow_loss: 0.6933 - transformer_accuracy: 2.5537e-05 - flow_accuracy: 0.4489 - val_loss: 1.4124e-04 - val_transformer_loss: 1.4124e-04 - val_flow_loss: 0.4286 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3672 - 51s/epoch - 511ms/step\n",
            "Epoch 124/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.1085e-04 - transformer_loss: 1.1085e-04 - flow_loss: 0.6937 - transformer_accuracy: 2.5391e-05 - flow_accuracy: 0.4466 - val_loss: 1.3879e-04 - val_transformer_loss: 1.3879e-04 - val_flow_loss: 0.4127 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3977 - 51s/epoch - 511ms/step\n",
            "Epoch 125/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.1023e-04 - transformer_loss: 1.1023e-04 - flow_loss: 0.6959 - transformer_accuracy: 2.3755e-05 - flow_accuracy: 0.4481 - val_loss: 1.3685e-04 - val_transformer_loss: 1.3685e-04 - val_flow_loss: 0.4292 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3843 - 51s/epoch - 511ms/step\n",
            "Epoch 126/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 126: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0941e-04 - transformer_loss: 1.0941e-04 - flow_loss: 0.6970 - transformer_accuracy: 2.4414e-05 - flow_accuracy: 0.4472 - val_loss: 1.3751e-04 - val_transformer_loss: 1.3751e-04 - val_flow_loss: 0.4217 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4092 - 51s/epoch - 511ms/step\n",
            "Epoch 127/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 127: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.1042e-04 - transformer_loss: 1.1042e-04 - flow_loss: 0.7005 - transformer_accuracy: 2.4121e-05 - flow_accuracy: 0.4486 - val_loss: 1.4434e-04 - val_transformer_loss: 1.4434e-04 - val_flow_loss: 0.4225 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3953 - 52s/epoch - 516ms/step\n",
            "Epoch 128/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 128: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.1028e-04 - transformer_loss: 1.1028e-04 - flow_loss: 0.6985 - transformer_accuracy: 2.3438e-05 - flow_accuracy: 0.4474 - val_loss: 1.4385e-04 - val_transformer_loss: 1.4385e-04 - val_flow_loss: 0.4292 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3948 - 52s/epoch - 518ms/step\n",
            "Epoch 129/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 129: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0911e-04 - transformer_loss: 1.0911e-04 - flow_loss: 0.6995 - transformer_accuracy: 2.5195e-05 - flow_accuracy: 0.4470 - val_loss: 1.4117e-04 - val_transformer_loss: 1.4117e-04 - val_flow_loss: 0.4197 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3655 - 51s/epoch - 511ms/step\n",
            "Epoch 130/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 130: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0873e-04 - transformer_loss: 1.0873e-04 - flow_loss: 0.6972 - transformer_accuracy: 2.5806e-05 - flow_accuracy: 0.4452 - val_loss: 1.4056e-04 - val_transformer_loss: 1.4056e-04 - val_flow_loss: 0.4346 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3901 - 51s/epoch - 512ms/step\n",
            "Epoch 131/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 131: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0894e-04 - transformer_loss: 1.0894e-04 - flow_loss: 0.7004 - transformer_accuracy: 2.4219e-05 - flow_accuracy: 0.4455 - val_loss: 1.4352e-04 - val_transformer_loss: 1.4352e-04 - val_flow_loss: 0.4088 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3938 - 52s/epoch - 515ms/step\n",
            "Epoch 132/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 132: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0833e-04 - transformer_loss: 1.0833e-04 - flow_loss: 0.7011 - transformer_accuracy: 2.4048e-05 - flow_accuracy: 0.4465 - val_loss: 1.4011e-04 - val_transformer_loss: 1.4011e-04 - val_flow_loss: 0.4284 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4265 - 52s/epoch - 518ms/step\n",
            "Epoch 133/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 133: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0876e-04 - transformer_loss: 1.0876e-04 - flow_loss: 0.7026 - transformer_accuracy: 2.6245e-05 - flow_accuracy: 0.4480 - val_loss: 1.3458e-04 - val_transformer_loss: 1.3458e-04 - val_flow_loss: 0.4066 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3721 - 52s/epoch - 516ms/step\n",
            "Epoch 134/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 134: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0785e-04 - transformer_loss: 1.0785e-04 - flow_loss: 0.7033 - transformer_accuracy: 2.5000e-05 - flow_accuracy: 0.4463 - val_loss: 1.3555e-04 - val_transformer_loss: 1.3555e-04 - val_flow_loss: 0.4549 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3655 - 51s/epoch - 514ms/step\n",
            "Epoch 135/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 135: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0893e-04 - transformer_loss: 1.0893e-04 - flow_loss: 0.7054 - transformer_accuracy: 2.4341e-05 - flow_accuracy: 0.4463 - val_loss: 1.3542e-04 - val_transformer_loss: 1.3542e-04 - val_flow_loss: 0.4357 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3801 - 52s/epoch - 518ms/step\n",
            "Epoch 136/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 136: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0715e-04 - transformer_loss: 1.0715e-04 - flow_loss: 0.7028 - transformer_accuracy: 2.4756e-05 - flow_accuracy: 0.4458 - val_loss: 1.3599e-04 - val_transformer_loss: 1.3599e-04 - val_flow_loss: 0.4556 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3679 - 51s/epoch - 511ms/step\n",
            "Epoch 137/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 137: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0765e-04 - transformer_loss: 1.0765e-04 - flow_loss: 0.7038 - transformer_accuracy: 2.4243e-05 - flow_accuracy: 0.4468 - val_loss: 1.4127e-04 - val_transformer_loss: 1.4127e-04 - val_flow_loss: 0.4481 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3936 - 51s/epoch - 514ms/step\n",
            "Epoch 138/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 138: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0586e-04 - transformer_loss: 1.0586e-04 - flow_loss: 0.7010 - transformer_accuracy: 2.3950e-05 - flow_accuracy: 0.4469 - val_loss: 1.3836e-04 - val_transformer_loss: 1.3836e-04 - val_flow_loss: 0.4445 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4045 - 52s/epoch - 517ms/step\n",
            "Epoch 139/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 139: val_loss improved from 0.00013 to 0.00013, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.0652e-04 - transformer_loss: 1.0652e-04 - flow_loss: 0.7046 - transformer_accuracy: 2.3926e-05 - flow_accuracy: 0.4459 - val_loss: 1.3260e-04 - val_transformer_loss: 1.3260e-04 - val_flow_loss: 0.4270 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4382 - 52s/epoch - 518ms/step\n",
            "Epoch 140/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 140: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0625e-04 - transformer_loss: 1.0625e-04 - flow_loss: 0.7059 - transformer_accuracy: 2.2876e-05 - flow_accuracy: 0.4479 - val_loss: 1.3859e-04 - val_transformer_loss: 1.3859e-04 - val_flow_loss: 0.4263 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3530 - 51s/epoch - 510ms/step\n",
            "Epoch 141/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 141: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0605e-04 - transformer_loss: 1.0605e-04 - flow_loss: 0.7055 - transformer_accuracy: 2.3340e-05 - flow_accuracy: 0.4456 - val_loss: 1.3433e-04 - val_transformer_loss: 1.3433e-04 - val_flow_loss: 0.4482 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3857 - 52s/epoch - 515ms/step\n",
            "Epoch 142/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 142: val_loss improved from 0.00013 to 0.00013, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.0644e-04 - transformer_loss: 1.0644e-04 - flow_loss: 0.7101 - transformer_accuracy: 2.3682e-05 - flow_accuracy: 0.4445 - val_loss: 1.3198e-04 - val_transformer_loss: 1.3198e-04 - val_flow_loss: 0.4519 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3982 - 52s/epoch - 523ms/step\n",
            "Epoch 143/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 143: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0607e-04 - transformer_loss: 1.0607e-04 - flow_loss: 0.7089 - transformer_accuracy: 2.3877e-05 - flow_accuracy: 0.4470 - val_loss: 1.3575e-04 - val_transformer_loss: 1.3575e-04 - val_flow_loss: 0.4354 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4006 - 51s/epoch - 513ms/step\n",
            "Epoch 144/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 144: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0536e-04 - transformer_loss: 1.0536e-04 - flow_loss: 0.7073 - transformer_accuracy: 2.4878e-05 - flow_accuracy: 0.4467 - val_loss: 1.4075e-04 - val_transformer_loss: 1.4075e-04 - val_flow_loss: 0.4294 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3848 - 51s/epoch - 511ms/step\n",
            "Epoch 145/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 145: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0521e-04 - transformer_loss: 1.0521e-04 - flow_loss: 0.7103 - transformer_accuracy: 2.3975e-05 - flow_accuracy: 0.4459 - val_loss: 1.4361e-04 - val_transformer_loss: 1.4361e-04 - val_flow_loss: 0.4164 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3718 - 51s/epoch - 511ms/step\n",
            "Epoch 146/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 146: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0536e-04 - transformer_loss: 1.0536e-04 - flow_loss: 0.7104 - transformer_accuracy: 2.3975e-05 - flow_accuracy: 0.4462 - val_loss: 1.4086e-04 - val_transformer_loss: 1.4086e-04 - val_flow_loss: 0.4279 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3899 - 51s/epoch - 511ms/step\n",
            "Epoch 147/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 147: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0512e-04 - transformer_loss: 1.0512e-04 - flow_loss: 0.7103 - transformer_accuracy: 2.3486e-05 - flow_accuracy: 0.4456 - val_loss: 1.4191e-04 - val_transformer_loss: 1.4191e-04 - val_flow_loss: 0.4345 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4326 - 51s/epoch - 510ms/step\n",
            "Epoch 148/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 148: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0487e-04 - transformer_loss: 1.0487e-04 - flow_loss: 0.7120 - transformer_accuracy: 2.4829e-05 - flow_accuracy: 0.4448 - val_loss: 1.3879e-04 - val_transformer_loss: 1.3879e-04 - val_flow_loss: 0.4307 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4226 - 51s/epoch - 511ms/step\n",
            "Epoch 149/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 149: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0575e-04 - transformer_loss: 1.0575e-04 - flow_loss: 0.7138 - transformer_accuracy: 2.4390e-05 - flow_accuracy: 0.4465 - val_loss: 1.4226e-04 - val_transformer_loss: 1.4226e-04 - val_flow_loss: 0.4222 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4001 - 51s/epoch - 511ms/step\n",
            "Epoch 150/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 150: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0417e-04 - transformer_loss: 1.0417e-04 - flow_loss: 0.7134 - transformer_accuracy: 2.4658e-05 - flow_accuracy: 0.4452 - val_loss: 1.3524e-04 - val_transformer_loss: 1.3524e-04 - val_flow_loss: 0.4261 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4233 - 51s/epoch - 514ms/step\n",
            "Epoch 151/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 151: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0390e-04 - transformer_loss: 1.0390e-04 - flow_loss: 0.7108 - transformer_accuracy: 2.4731e-05 - flow_accuracy: 0.4449 - val_loss: 1.4376e-04 - val_transformer_loss: 1.4376e-04 - val_flow_loss: 0.4180 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3940 - 52s/epoch - 519ms/step\n",
            "Epoch 152/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 152: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0373e-04 - transformer_loss: 1.0373e-04 - flow_loss: 0.7141 - transformer_accuracy: 2.4683e-05 - flow_accuracy: 0.4467 - val_loss: 1.3575e-04 - val_transformer_loss: 1.3575e-04 - val_flow_loss: 0.4527 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4077 - 51s/epoch - 512ms/step\n",
            "Epoch 153/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 153: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0394e-04 - transformer_loss: 1.0394e-04 - flow_loss: 0.7144 - transformer_accuracy: 2.4390e-05 - flow_accuracy: 0.4460 - val_loss: 1.3600e-04 - val_transformer_loss: 1.3600e-04 - val_flow_loss: 0.4005 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3660 - 51s/epoch - 511ms/step\n",
            "Epoch 154/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 154: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0401e-04 - transformer_loss: 1.0401e-04 - flow_loss: 0.7145 - transformer_accuracy: 2.4634e-05 - flow_accuracy: 0.4447 - val_loss: 1.3513e-04 - val_transformer_loss: 1.3513e-04 - val_flow_loss: 0.4325 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3784 - 52s/epoch - 519ms/step\n",
            "Epoch 155/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 155: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0311e-04 - transformer_loss: 1.0311e-04 - flow_loss: 0.7168 - transformer_accuracy: 2.4146e-05 - flow_accuracy: 0.4459 - val_loss: 1.3357e-04 - val_transformer_loss: 1.3357e-04 - val_flow_loss: 0.4344 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3965 - 52s/epoch - 523ms/step\n",
            "Epoch 156/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 156: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0257e-04 - transformer_loss: 1.0257e-04 - flow_loss: 0.7155 - transformer_accuracy: 2.3926e-05 - flow_accuracy: 0.4481 - val_loss: 1.3591e-04 - val_transformer_loss: 1.3591e-04 - val_flow_loss: 0.4411 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3640 - 52s/epoch - 522ms/step\n",
            "Epoch 157/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 157: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0311e-04 - transformer_loss: 1.0311e-04 - flow_loss: 0.7189 - transformer_accuracy: 2.4707e-05 - flow_accuracy: 0.4448 - val_loss: 1.3467e-04 - val_transformer_loss: 1.3467e-04 - val_flow_loss: 0.4488 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3730 - 51s/epoch - 515ms/step\n",
            "Epoch 158/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 158: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0256e-04 - transformer_loss: 1.0256e-04 - flow_loss: 0.7183 - transformer_accuracy: 2.4219e-05 - flow_accuracy: 0.4461 - val_loss: 1.3200e-04 - val_transformer_loss: 1.3200e-04 - val_flow_loss: 0.4373 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3533 - 52s/epoch - 518ms/step\n",
            "Epoch 159/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 159: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0312e-04 - transformer_loss: 1.0312e-04 - flow_loss: 0.7189 - transformer_accuracy: 2.4780e-05 - flow_accuracy: 0.4432 - val_loss: 1.3450e-04 - val_transformer_loss: 1.3450e-04 - val_flow_loss: 0.4242 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3804 - 51s/epoch - 513ms/step\n",
            "Epoch 160/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 160: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0206e-04 - transformer_loss: 1.0206e-04 - flow_loss: 0.7157 - transformer_accuracy: 2.4731e-05 - flow_accuracy: 0.4439 - val_loss: 1.4038e-04 - val_transformer_loss: 1.4038e-04 - val_flow_loss: 0.4637 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4150 - 51s/epoch - 515ms/step\n",
            "Epoch 161/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 161: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0212e-04 - transformer_loss: 1.0212e-04 - flow_loss: 0.7167 - transformer_accuracy: 2.5269e-05 - flow_accuracy: 0.4452 - val_loss: 1.3481e-04 - val_transformer_loss: 1.3481e-04 - val_flow_loss: 0.4197 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3748 - 51s/epoch - 511ms/step\n",
            "Epoch 162/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 162: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0199e-04 - transformer_loss: 1.0199e-04 - flow_loss: 0.7194 - transformer_accuracy: 2.2632e-05 - flow_accuracy: 0.4430 - val_loss: 1.3302e-04 - val_transformer_loss: 1.3302e-04 - val_flow_loss: 0.4189 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3918 - 51s/epoch - 510ms/step\n",
            "Epoch 163/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 163: val_loss improved from 0.00013 to 0.00013, saving model to model.h5\n",
            "100/100 - 51s - loss: 1.0198e-04 - transformer_loss: 1.0198e-04 - flow_loss: 0.7200 - transformer_accuracy: 2.5049e-05 - flow_accuracy: 0.4443 - val_loss: 1.3170e-04 - val_transformer_loss: 1.3170e-04 - val_flow_loss: 0.4343 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4033 - 51s/epoch - 512ms/step\n",
            "Epoch 164/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 164: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0127e-04 - transformer_loss: 1.0127e-04 - flow_loss: 0.7209 - transformer_accuracy: 2.4341e-05 - flow_accuracy: 0.4423 - val_loss: 1.3267e-04 - val_transformer_loss: 1.3267e-04 - val_flow_loss: 0.4389 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3711 - 51s/epoch - 515ms/step\n",
            "Epoch 165/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 165: val_loss improved from 0.00013 to 0.00013, saving model to model.h5\n",
            "100/100 - 52s - loss: 1.0119e-04 - transformer_loss: 1.0119e-04 - flow_loss: 0.7220 - transformer_accuracy: 2.3047e-05 - flow_accuracy: 0.4451 - val_loss: 1.3136e-04 - val_transformer_loss: 1.3136e-04 - val_flow_loss: 0.4165 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3721 - 52s/epoch - 519ms/step\n",
            "Epoch 166/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 166: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 1.0144e-04 - transformer_loss: 1.0144e-04 - flow_loss: 0.7198 - transformer_accuracy: 2.5073e-05 - flow_accuracy: 0.4441 - val_loss: 1.3263e-04 - val_transformer_loss: 1.3263e-04 - val_flow_loss: 0.4471 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4285 - 52s/epoch - 520ms/step\n",
            "Epoch 167/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 167: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0033e-04 - transformer_loss: 1.0033e-04 - flow_loss: 0.7201 - transformer_accuracy: 2.4536e-05 - flow_accuracy: 0.4456 - val_loss: 1.3835e-04 - val_transformer_loss: 1.3835e-04 - val_flow_loss: 0.4794 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3960 - 51s/epoch - 514ms/step\n",
            "Epoch 168/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 168: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0134e-04 - transformer_loss: 1.0134e-04 - flow_loss: 0.7225 - transformer_accuracy: 2.3145e-05 - flow_accuracy: 0.4455 - val_loss: 1.3670e-04 - val_transformer_loss: 1.3670e-04 - val_flow_loss: 0.4622 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4111 - 51s/epoch - 511ms/step\n",
            "Epoch 169/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 169: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.9980e-05 - transformer_loss: 9.9980e-05 - flow_loss: 0.7224 - transformer_accuracy: 2.4805e-05 - flow_accuracy: 0.4441 - val_loss: 1.3417e-04 - val_transformer_loss: 1.3417e-04 - val_flow_loss: 0.4525 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3899 - 51s/epoch - 515ms/step\n",
            "Epoch 170/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 170: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0125e-04 - transformer_loss: 1.0125e-04 - flow_loss: 0.7234 - transformer_accuracy: 2.4512e-05 - flow_accuracy: 0.4438 - val_loss: 1.3313e-04 - val_transformer_loss: 1.3313e-04 - val_flow_loss: 0.4232 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4092 - 51s/epoch - 511ms/step\n",
            "Epoch 171/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 171: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.9715e-05 - transformer_loss: 9.9715e-05 - flow_loss: 0.7237 - transformer_accuracy: 2.4341e-05 - flow_accuracy: 0.4434 - val_loss: 1.3894e-04 - val_transformer_loss: 1.3894e-04 - val_flow_loss: 0.4265 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4290 - 51s/epoch - 510ms/step\n",
            "Epoch 172/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 172: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0001e-04 - transformer_loss: 1.0001e-04 - flow_loss: 0.7260 - transformer_accuracy: 2.4121e-05 - flow_accuracy: 0.4438 - val_loss: 1.4026e-04 - val_transformer_loss: 1.4026e-04 - val_flow_loss: 0.4118 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3826 - 51s/epoch - 512ms/step\n",
            "Epoch 173/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 173: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 1.0006e-04 - transformer_loss: 1.0006e-04 - flow_loss: 0.7237 - transformer_accuracy: 2.4268e-05 - flow_accuracy: 0.4434 - val_loss: 1.4214e-04 - val_transformer_loss: 1.4214e-04 - val_flow_loss: 0.4529 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3818 - 51s/epoch - 512ms/step\n",
            "Epoch 174/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 174: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.9669e-05 - transformer_loss: 9.9669e-05 - flow_loss: 0.7284 - transformer_accuracy: 2.4805e-05 - flow_accuracy: 0.4436 - val_loss: 1.4483e-04 - val_transformer_loss: 1.4483e-04 - val_flow_loss: 0.4323 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4238 - 51s/epoch - 510ms/step\n",
            "Epoch 175/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 175: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.9722e-05 - transformer_loss: 9.9722e-05 - flow_loss: 0.7270 - transformer_accuracy: 2.4487e-05 - flow_accuracy: 0.4450 - val_loss: 1.3610e-04 - val_transformer_loss: 1.3610e-04 - val_flow_loss: 0.4319 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3801 - 51s/epoch - 513ms/step\n",
            "Epoch 176/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 176: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.9989e-05 - transformer_loss: 9.9989e-05 - flow_loss: 0.7277 - transformer_accuracy: 2.2900e-05 - flow_accuracy: 0.4433 - val_loss: 1.3165e-04 - val_transformer_loss: 1.3165e-04 - val_flow_loss: 0.4550 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3826 - 52s/epoch - 522ms/step\n",
            "Epoch 177/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 177: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.8800e-05 - transformer_loss: 9.8800e-05 - flow_loss: 0.7255 - transformer_accuracy: 2.4512e-05 - flow_accuracy: 0.4446 - val_loss: 1.3365e-04 - val_transformer_loss: 1.3365e-04 - val_flow_loss: 0.4351 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3962 - 52s/epoch - 516ms/step\n",
            "Epoch 178/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 178: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.8445e-05 - transformer_loss: 9.8445e-05 - flow_loss: 0.7259 - transformer_accuracy: 2.4438e-05 - flow_accuracy: 0.4437 - val_loss: 1.3916e-04 - val_transformer_loss: 1.3916e-04 - val_flow_loss: 0.4403 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3657 - 52s/epoch - 519ms/step\n",
            "Epoch 179/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 179: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.8816e-05 - transformer_loss: 9.8816e-05 - flow_loss: 0.7252 - transformer_accuracy: 2.4780e-05 - flow_accuracy: 0.4436 - val_loss: 1.3350e-04 - val_transformer_loss: 1.3350e-04 - val_flow_loss: 0.4426 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3860 - 51s/epoch - 515ms/step\n",
            "Epoch 180/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 180: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.8354e-05 - transformer_loss: 9.8354e-05 - flow_loss: 0.7284 - transformer_accuracy: 2.5537e-05 - flow_accuracy: 0.4438 - val_loss: 1.3760e-04 - val_transformer_loss: 1.3760e-04 - val_flow_loss: 0.4538 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3943 - 52s/epoch - 516ms/step\n",
            "Epoch 181/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 181: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.8947e-05 - transformer_loss: 9.8947e-05 - flow_loss: 0.7278 - transformer_accuracy: 2.3755e-05 - flow_accuracy: 0.4444 - val_loss: 1.3436e-04 - val_transformer_loss: 1.3436e-04 - val_flow_loss: 0.4522 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3955 - 51s/epoch - 513ms/step\n",
            "Epoch 182/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 182: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.8354e-05 - transformer_loss: 9.8354e-05 - flow_loss: 0.7301 - transformer_accuracy: 2.4023e-05 - flow_accuracy: 0.4437 - val_loss: 1.3550e-04 - val_transformer_loss: 1.3550e-04 - val_flow_loss: 0.4465 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3889 - 52s/epoch - 516ms/step\n",
            "Epoch 183/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 183: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.8294e-05 - transformer_loss: 9.8294e-05 - flow_loss: 0.7307 - transformer_accuracy: 2.3950e-05 - flow_accuracy: 0.4459 - val_loss: 1.3980e-04 - val_transformer_loss: 1.3980e-04 - val_flow_loss: 0.4517 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3687 - 52s/epoch - 515ms/step\n",
            "Epoch 184/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 184: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.7684e-05 - transformer_loss: 9.7684e-05 - flow_loss: 0.7299 - transformer_accuracy: 2.2705e-05 - flow_accuracy: 0.4429 - val_loss: 1.3743e-04 - val_transformer_loss: 1.3743e-04 - val_flow_loss: 0.4441 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3857 - 51s/epoch - 514ms/step\n",
            "Epoch 185/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 185: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.8907e-05 - transformer_loss: 9.8907e-05 - flow_loss: 0.7319 - transformer_accuracy: 2.4609e-05 - flow_accuracy: 0.4430 - val_loss: 1.3404e-04 - val_transformer_loss: 1.3404e-04 - val_flow_loss: 0.4348 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3655 - 51s/epoch - 514ms/step\n",
            "Epoch 186/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 186: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.7537e-05 - transformer_loss: 9.7537e-05 - flow_loss: 0.7297 - transformer_accuracy: 2.4121e-05 - flow_accuracy: 0.4420 - val_loss: 1.3490e-04 - val_transformer_loss: 1.3490e-04 - val_flow_loss: 0.4524 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4165 - 52s/epoch - 516ms/step\n",
            "Epoch 187/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 187: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.8134e-05 - transformer_loss: 9.8134e-05 - flow_loss: 0.7321 - transformer_accuracy: 2.5049e-05 - flow_accuracy: 0.4427 - val_loss: 1.3291e-04 - val_transformer_loss: 1.3291e-04 - val_flow_loss: 0.4447 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3787 - 52s/epoch - 516ms/step\n",
            "Epoch 188/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 188: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.7109e-05 - transformer_loss: 9.7109e-05 - flow_loss: 0.7320 - transformer_accuracy: 2.4390e-05 - flow_accuracy: 0.4445 - val_loss: 1.3731e-04 - val_transformer_loss: 1.3731e-04 - val_flow_loss: 0.4368 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3596 - 52s/epoch - 516ms/step\n",
            "Epoch 189/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 189: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.7974e-05 - transformer_loss: 9.7974e-05 - flow_loss: 0.7308 - transformer_accuracy: 2.5488e-05 - flow_accuracy: 0.4422 - val_loss: 1.3856e-04 - val_transformer_loss: 1.3856e-04 - val_flow_loss: 0.4499 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3931 - 52s/epoch - 515ms/step\n",
            "Epoch 190/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 190: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.6949e-05 - transformer_loss: 9.6949e-05 - flow_loss: 0.7319 - transformer_accuracy: 2.5073e-05 - flow_accuracy: 0.4437 - val_loss: 1.3913e-04 - val_transformer_loss: 1.3913e-04 - val_flow_loss: 0.4504 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4045 - 51s/epoch - 512ms/step\n",
            "Epoch 191/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 191: val_loss did not improve from 0.00013\n",
            "100/100 - 51s - loss: 9.7634e-05 - transformer_loss: 9.7634e-05 - flow_loss: 0.7352 - transformer_accuracy: 2.5171e-05 - flow_accuracy: 0.4442 - val_loss: 1.4133e-04 - val_transformer_loss: 1.4133e-04 - val_flow_loss: 0.4421 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4153 - 51s/epoch - 511ms/step\n",
            "Epoch 192/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 192: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.6791e-05 - transformer_loss: 9.6791e-05 - flow_loss: 0.7338 - transformer_accuracy: 2.3340e-05 - flow_accuracy: 0.4430 - val_loss: 1.4215e-04 - val_transformer_loss: 1.4215e-04 - val_flow_loss: 0.4682 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3638 - 52s/epoch - 516ms/step\n",
            "Epoch 193/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 193: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.7355e-05 - transformer_loss: 9.7355e-05 - flow_loss: 0.7328 - transformer_accuracy: 2.5684e-05 - flow_accuracy: 0.4420 - val_loss: 1.3840e-04 - val_transformer_loss: 1.3840e-04 - val_flow_loss: 0.4529 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4167 - 52s/epoch - 516ms/step\n",
            "Epoch 194/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 194: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.5995e-05 - transformer_loss: 9.5995e-05 - flow_loss: 0.7299 - transformer_accuracy: 2.4951e-05 - flow_accuracy: 0.4429 - val_loss: 1.3586e-04 - val_transformer_loss: 1.3586e-04 - val_flow_loss: 0.4303 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3557 - 52s/epoch - 516ms/step\n",
            "Epoch 195/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 195: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.6705e-05 - transformer_loss: 9.6705e-05 - flow_loss: 0.7370 - transformer_accuracy: 2.3926e-05 - flow_accuracy: 0.4437 - val_loss: 1.3812e-04 - val_transformer_loss: 1.3812e-04 - val_flow_loss: 0.4172 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3594 - 52s/epoch - 517ms/step\n",
            "Epoch 196/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 196: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.6292e-05 - transformer_loss: 9.6292e-05 - flow_loss: 0.7346 - transformer_accuracy: 2.3657e-05 - flow_accuracy: 0.4458 - val_loss: 1.3738e-04 - val_transformer_loss: 1.3738e-04 - val_flow_loss: 0.4786 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3918 - 52s/epoch - 517ms/step\n",
            "Epoch 197/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 197: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.6234e-05 - transformer_loss: 9.6234e-05 - flow_loss: 0.7366 - transformer_accuracy: 2.3730e-05 - flow_accuracy: 0.4423 - val_loss: 1.3744e-04 - val_transformer_loss: 1.3744e-04 - val_flow_loss: 0.4318 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.4055 - 52s/epoch - 516ms/step\n",
            "Epoch 198/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 198: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.6497e-05 - transformer_loss: 9.6497e-05 - flow_loss: 0.7373 - transformer_accuracy: 2.3975e-05 - flow_accuracy: 0.4441 - val_loss: 1.4581e-04 - val_transformer_loss: 1.4581e-04 - val_flow_loss: 0.4525 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3867 - 52s/epoch - 517ms/step\n",
            "Epoch 199/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 199: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.6413e-05 - transformer_loss: 9.6413e-05 - flow_loss: 0.7375 - transformer_accuracy: 2.4561e-05 - flow_accuracy: 0.4420 - val_loss: 1.4111e-04 - val_transformer_loss: 1.4111e-04 - val_flow_loss: 0.4456 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3928 - 52s/epoch - 518ms/step\n",
            "Epoch 200/200\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,transformer_loss,flow_loss,transformer_accuracy,flow_accuracy,val_loss,val_transformer_loss,val_flow_loss,val_transformer_accuracy,val_flow_accuracy\n",
            "\n",
            "Epoch 200: val_loss did not improve from 0.00013\n",
            "100/100 - 52s - loss: 9.6234e-05 - transformer_loss: 9.6234e-05 - flow_loss: 0.7362 - transformer_accuracy: 2.4927e-05 - flow_accuracy: 0.4417 - val_loss: 1.4031e-04 - val_transformer_loss: 1.4031e-04 - val_flow_loss: 0.4526 - val_transformer_accuracy: 0.0000e+00 - val_flow_accuracy: 0.3975 - 52s/epoch - 516ms/step\n",
            "Training Time:10407.607284784317s\n"
          ]
        }
      ],
      "source": [
        "nb_epochs =200\n",
        "steps_per_epoch =100\n",
        "import time\n",
        "start=time.time()\n",
        "hist = vxm_model.fit(train_generator,\n",
        "                               epochs=nb_epochs,\n",
        "                               steps_per_epoch=steps_per_epoch,\n",
        "                               verbose=2,\n",
        "                               callbacks=[es,checkpoint],\n",
        "                               validation_data=val_generator(data_dir,1,1584,.3)\n",
        "                    );\n",
        "stop=time.time()\n",
        "print(f\"Training Time:{stop-start}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9TpdYEVf0Tas"
      },
      "outputs": [],
      "source": [
        "vxm_model.save(\"/content/drive/MyDrive/final/new/MSE_la0_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vxm_model.save_weights(\"/content/drive/MyDrive/data/final/MSE_la0_weight1.h5\")"
      ],
      "metadata": {
        "id": "-jgJrCcGdfei"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "QpCyFLYxYxG0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/data/final/M01', 'wb') as file_pi:\n",
        "     pickle.dump(hist.history, file_pi)"
      ],
      "metadata": {
        "id": "os3ZIIP7uoI7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = pickle.load(open('/trainHistoryDict', \"rb\"))"
      ],
      "metadata": {
        "id": "tjdgEQ9iZK9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flVUoksh0Tat"
      },
      "outputs": [],
      "source": [
        "def plot_history(hist, loss_name='loss'):\n",
        "    # Simple function to plot training history.\n",
        "    plt.figure()\n",
        "    plt.plot(hist.epoch, hist.history[loss_name], '.-')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_Navfe80Tat"
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyidT-ng0Tau",
        "outputId": "5df308d6-395e-4867-d28c-f41ee478e353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_history(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS_d7ebW0Tau"
      },
      "outputs": [],
      "source": [
        "data_dir_TEST='/home/mahdi/Desktop/data_selection_D7'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyGKUTue0Tau"
      },
      "outputs": [],
      "source": [
        "# let's get some data\n",
        "val_generator = data_generator(data_dir_TEST,32,m,.3)\n",
        "val_input, _ = next(val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qJXWceq0Tav"
      },
      "outputs": [],
      "source": [
        "val_pred = vxm_model.predict(val_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qQMN3v10Tav"
      },
      "outputs": [],
      "source": [
        "# visualize\n",
        "images = [img[18, :, :, 0] for img in val_input + val_pred] \n",
        "titles = ['moving', 'fixed', 'moved', 'flow']\n",
        "ne.plot.slices(images, titles=titles, cmaps=['gray'], do_colorbars=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWsn84Ux0Tav"
      },
      "outputs": [],
      "source": [
        "ne.plot.flow([val_pred[1][18].squeeze()], width=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwXQkGbB0Taw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "train_with validation data.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}