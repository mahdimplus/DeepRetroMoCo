{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mahdimplus/DeepRetroMoco/blob/main/functions.ipynb)"
      ],
      "metadata": {
        "id": "IP1OR5KA4m2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install voxelmorph"
      ],
      "metadata": {
        "id": "EAnDfgvm54v_",
        "outputId": "45253d05-3256-4a56-fea8-7f3bdd290af3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting voxelmorph\n",
            "  Downloading voxelmorph-0.1-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▍                           | 10 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 61 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 71 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 75 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (1.19.5)\n",
            "Collecting neurite\n",
            "  Downloading neurite-0.1-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (3.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (1.4.1)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (3.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from voxelmorph) (0.18.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->voxelmorph) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (4.62.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (3.2.2)\n",
            "Collecting pystrum\n",
            "  Downloading pystrum-0.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from neurite->voxelmorph) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->neurite->voxelmorph) (1.3.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (2021.11.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->voxelmorph) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->neurite->voxelmorph) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->neurite->voxelmorph) (1.1.0)\n",
            "Installing collected packages: pystrum, neurite, voxelmorph\n",
            "Successfully installed neurite-0.1 pystrum-0.1 voxelmorph-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "de_Q_MTowDbf"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from nibabel.affines import apply_affine\n",
        "import time\n",
        "import voxelmorph as vxm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aum9N4dnwDbg"
      },
      "source": [
        "### load data in specific shape (64*64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cgr5yoYdwDbi"
      },
      "outputs": [],
      "source": [
        "def load_m (file_path):\n",
        "    \n",
        "    img = nib.load(file_path)\n",
        "    img_data = img.get_fdata()\n",
        "    \n",
        "    if img.shape[0:2]!=(64,64):\n",
        "    \n",
        "        img_data = img_data[23:87,23:87,:,:]\n",
        "        \n",
        "    if not (file_path.endswith(\".nii\") or file_path.endswith(\".nii.gz\")):\n",
        "        raise ValueError(\n",
        "              f\"Nifti file path must end with .nii or .nii.gz, got {file_path}.\"\n",
        "                        )\n",
        "    return img_data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uHSmykNwDbj"
      },
      "source": [
        "### load data in specific shape (64*64) with header data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bF2FJT7wDbj"
      },
      "outputs": [],
      "source": [
        "def load_with_head (file_path: str):\n",
        "    \n",
        "    img = nib.load(file_path)\n",
        "    img_data = img.get_fdata()\n",
        "    if img.shape[0:2]!=(64,64):\n",
        "    \n",
        "        img_data = img_data[23:87,23:87,:,:]\n",
        "        header=img.header  \n",
        "        ## edit the header for shape\n",
        "        header['dim'][1:5]=img_data.shape\n",
        "        \n",
        "    if not (file_path.endswith(\".nii\") or file_path.endswith(\".nii.gz\")):\n",
        "        raise ValueError(\n",
        "              f\"Nifti file path must end with .nii or .nii.gz, got {file_path}.\"\n",
        "                        )\n",
        "    return img_data ,img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xar_u6SIwDbk"
      },
      "source": [
        "### list of name and number of data in a direction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0VI-ErVwDbk"
      },
      "outputs": [],
      "source": [
        "def count (data_dir):\n",
        "    train_dir = os.path.join(data_dir)\n",
        "\n",
        "    train_data_num = []\n",
        "    for file in os.listdir(train_dir):\n",
        "            train_data_num.append([file])\n",
        "    train_data_num=np.array(train_data_num) \n",
        "    n=train_data_num.shape[0] \n",
        "\n",
        "    return n,train_data_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLWxG07xwDbl"
      },
      "source": [
        "### calculate maximum intensity in a direction between all data for normalization "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE1_j53WwDbl"
      },
      "outputs": [],
      "source": [
        "def maxx (data_dir):\n",
        "    n,train_data_num=count(data_dir)\n",
        "    start=0\n",
        "    \n",
        "    for i in range(n):\n",
        "        \n",
        "        d=load_m(data_dir+'/'+str(train_data_num[i][0]))\n",
        "        maxx=d.max()\n",
        "        \n",
        "        if maxx>=start:\n",
        "            start=maxx\n",
        "            \n",
        "    return start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWeqIMRqwDbl"
      },
      "source": [
        "###  prepare input (moved , fix) and ground truth (ref , deformation map) for training network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxJIOrOuwDbl"
      },
      "outputs": [],
      "source": [
        "def data_generator(data_dir, batch_size,m,split):\n",
        "    \"\"\"4\n",
        "    Generator that takes in data of size [N, H, W], and yields data for\n",
        "    our custom vxm model. Note that we need to provide numpy data for each\n",
        "    input, and each output.\n",
        "\n",
        "    inputs:  moving [bs, H, W, 1], fixed image [bs, H, W, 1]\n",
        "    outputs: moved image [bs, H, W, 1], zero-gradient [bs, H, W, 2]\n",
        "    \n",
        "    m= maximum between all subject \n",
        "    split= percent of validation data\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    n,train_data_num=count(data_dir)\n",
        "    n_train=n-int(split*n)\n",
        " \n",
        "    \n",
        "    subject_ID=random.randint(0,n_train-1)\n",
        "    d=load_m(data_dir+'/'+str(train_data_num[subject_ID][0]))\n",
        "\n",
        "    \n",
        "    s=d.shape[2]\n",
        "    slice_ID =random.randint(0,s-1)\n",
        "    v=d.shape[3]\n",
        "    \n",
        " # preliminary sizing\n",
        "    vol_shape = d.shape[:2] # extract data shape\n",
        "    ndims = len(vol_shape)\n",
        "    \n",
        "    \n",
        "    d=d[:,:,slice_ID,:]\n",
        "    d = np.einsum('jki->ijk', d)\n",
        "\n",
        "    \n",
        "    \n",
        "   \n",
        "    \n",
        "    # prepare a zero array the size of the deformation\n",
        "    # we'll explain this below\n",
        "    zero_phi = np.zeros([batch_size, *vol_shape, ndims])\n",
        "    \n",
        "    while True:\n",
        "        # prepare inputs:\n",
        "        # images need to be of the size [batch_size, H, W, 1]\n",
        "        idx1 = np.random.randint(0, v, size=batch_size)\n",
        "        moving_images = d[idx1, ..., np.newaxis]\n",
        "        moving_images=moving_images/m\n",
        "        \n",
        "        idx2 = np.random.randint(0, v, size=batch_size)\n",
        "        fixed_images = d[idx2, ..., np.newaxis]\n",
        "        fixed_images=fixed_images/m\n",
        "        \n",
        "        inputs = [moving_images, fixed_images]\n",
        "        \n",
        "        # prepare outputs (the 'true' moved image):\n",
        "        # of course, we don't have this, but we know we want to compare \n",
        "        # the resulting moved image with the fixed image. \n",
        "        # we also wish to penalize the deformation field. \n",
        "        outputs = [fixed_images, zero_phi]\n",
        "        \n",
        "        yield (inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C2t12d-wDbm"
      },
      "source": [
        "### prepare data for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMlJTVmEwDbn"
      },
      "outputs": [],
      "source": [
        "def val_generator(data_dir, batch_size,m,split):\n",
        "    \"\"\"4\n",
        "    Generator that takes in data of size [N, H, W], and yields data for\n",
        "    our custom vxm model. Note that we need to provide numpy data for each\n",
        "    input, and each output.\n",
        "\n",
        "    inputs:  moving [bs, H, W, 1], fixed image [bs, H, W, 1]\n",
        "    outputs: moved image [bs, H, W, 1], zero-gradient [bs, H, W, 2]\n",
        "    \n",
        "    m= maximum between all subject \n",
        "    split= percent of validation data\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    n,train_data_num=count(data_dir)\n",
        "    n_train=n-int(split*n)\n",
        "    a=n_train\n",
        "    \n",
        "    \n",
        "    subject_ID=random.randint(a,n-1)\n",
        "    d=load_m(data_dir+'/'+str(train_data_num[subject_ID][0]))\n",
        "\n",
        "    \n",
        "    s=d.shape[2]\n",
        "    slice_ID =random.randint(0,s-1)\n",
        "    v=d.shape[3]\n",
        "    \n",
        " # preliminary sizing\n",
        "    vol_shape = d.shape[:2] # extract data shape\n",
        "    ndims = len(vol_shape)\n",
        "    \n",
        "    \n",
        "    d=d[:,:,slice_ID,:]\n",
        "    d = np.einsum('jki->ijk', d)\n",
        "\n",
        "    \n",
        "    \n",
        "   \n",
        "    \n",
        "    # prepare a zero array the size of the deformation\n",
        "    # we'll explain this below\n",
        "    zero_phi = np.zeros([batch_size, *vol_shape, ndims])\n",
        "    \n",
        "    # prepare inputs:\n",
        "    # images need to be of the size [batch_size, H, W, 1]\n",
        "    idx1 = np.random.randint(0, v, size=batch_size)\n",
        "    moving_images = d[idx1, ..., np.newaxis]\n",
        "    moving_images=moving_images/m\n",
        "\n",
        "    idx2 = np.random.randint(0, v, size=batch_size)\n",
        "    fixed_images = d[idx2, ..., np.newaxis]\n",
        "    fixed_images=fixed_images/m\n",
        "\n",
        "    inputs = [moving_images, fixed_images]\n",
        "\n",
        "    # prepare outputs (the 'true' moved image):\n",
        "    # of course, we don't have this, but we know we want to compare \n",
        "    # the resulting moved image with the fixed image. \n",
        "    # we also wish to penalize the deformation field. \n",
        "    outputs = [fixed_images,zero_phi]\n",
        "\n",
        "    return (inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xaHSeKrwDbn"
      },
      "source": [
        "### change angle format  and nearest neighborhod and apply affine matrix   for augmentation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLPjvbYiwDbo"
      },
      "outputs": [],
      "source": [
        "def a(teta):\n",
        "    return   (teta*np.pi)/180\n",
        "\n",
        "def nearest_neighbors(i, j, M, T_inv):\n",
        "    x_max, y_max = M.shape[0] - 1, M.shape[1] - 1\n",
        "    \n",
        "    x, y, k = apply_affine(T_inv, np.array([i, j, 1]))\n",
        "   \n",
        "    if x<0 or y<0:\n",
        "            x=0\n",
        "            y=0\n",
        "    if x>=x_max+1 or y>=y_max+1:\n",
        "            x=0\n",
        "            y=0 \n",
        "            \n",
        "            \n",
        "    if np.floor(x) == x and np.floor(y) == y:\n",
        "        x, y = int(x), int(y)\n",
        "        return M[x, y]\n",
        "    \n",
        "    if np.abs(np.floor(x) - x) < np.abs(np.ceil(x) - x):\n",
        "        x = int(np.floor(x))\n",
        "    else:\n",
        "        x = int(np.ceil(x))\n",
        "    if np.abs(np.floor(y) - y) < np.abs(np.ceil(y) - y):\n",
        "        y = int(np.floor(y))\n",
        "    else:\n",
        "        y = int(np.ceil(y))\n",
        "        \n",
        "    if x > x_max:\n",
        "        x = x_max\n",
        "    if y > y_max:\n",
        "        y = y_max\n",
        "    return M[x, y]\n",
        "\n",
        "   \n",
        "\n",
        "def affine_matrix():\n",
        "    t=random.randint(-5, 5)\n",
        "    cos_gamma = np.cos(a(t))\n",
        "    sin_gamma = np.sin(a(t))\n",
        "    x=random.randint(-3, 3)\n",
        "    y=random.randint(-6, 6)\n",
        "    T=np.array([[cos_gamma,-sin_gamma,0,x],\n",
        "                 [sin_gamma,cos_gamma,0,y],\n",
        "                 [0,0,1,0],\n",
        "                 [0,0,0,1]])\n",
        "\n",
        "    return T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB-9pACmwDbo"
      },
      "source": [
        "### Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cDagMO1wDbo"
      },
      "outputs": [],
      "source": [
        "def augsb(ref,volume,affine_matrix):\n",
        "    tdim,xdim,ydim,tdim  = ref.shape\n",
        "    img_transformed = np.zeros((xdim, ydim), dtype=np.float64)\n",
        "\n",
        "    for i, row in enumerate(ref[volume,:,:,0]):\n",
        "        for j, col in enumerate(row):\n",
        "            pixel_data = ref[volume,i, j, 0]\n",
        "\n",
        "            input_coords = np.array([i, j, 1])\n",
        "            i_out, j_out,k= apply_affine(affine_matrix, input_coords)\n",
        "        \n",
        "            if i_out<0 or j_out<0:\n",
        "                i_out=0\n",
        "                j_out=0\n",
        "            if i_out>=xdim or j_out>=ydim:\n",
        "                i_out=0\n",
        "                j_out=0   \n",
        "                \n",
        "            img_transformed[int(i_out),int(j_out)] = pixel_data\n",
        "    \n",
        "    \n",
        "    T_inv = np.linalg.inv(affine_matrix)\n",
        "    img_nn = np.ones((xdim, ydim), dtype=np.float64)\n",
        "    for i, row in enumerate(img_transformed):\n",
        "        for j, col in enumerate(row):\n",
        "\n",
        "            img_nn[i, j] = nearest_neighbors(i, j, ref[volume,:,:,0], T_inv)\n",
        "            \n",
        "    return   img_nn  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOMIuhvRwDbp"
      },
      "source": [
        "### prepare data for augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQGLRbamwDbp"
      },
      "outputs": [],
      "source": [
        "def affine_generator(data_dir,batch_size,m,split):\n",
        "\n",
        "    n,train_data_num=count(data_dir)\n",
        "    n_train=n-int(split*n)\n",
        "    \n",
        "\n",
        "\n",
        "    subject_ID=random.randint(0,n_train-1)\n",
        "    d=load_m(data_dir+'/'+str(train_data_num[subject_ID][0]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    s=d.shape[2]\n",
        "    slice_ID =random.randint(0,s-1)\n",
        "\n",
        "    v=d.shape[3]\n",
        "\n",
        "    # preliminary sizing\n",
        "    vol_shape = d.shape[:2] # extract data shape\n",
        "    ndims = len(vol_shape)\n",
        "\n",
        "\n",
        "    d=d[:,:,slice_ID,:]\n",
        "    d = np.einsum('jki->ijk', d)\n",
        "\n",
        "\n",
        "    y=[]\n",
        "    for i in range(batch_size):\n",
        "        y.append(affine_matrix())\n",
        "    y=np.array(y)\n",
        "\n",
        "\n",
        "    # prepare a zero array the size of the deformation\n",
        "    # we'll explain this below\n",
        "    zero_phi = np.zeros([batch_size, *vol_shape, ndims])\n",
        "\n",
        "    # prepare inputs:\n",
        "    # images need to be of the size [batch_size, H, W, 1]\n",
        "    while True:\n",
        "        idx2 = np.random.randint(0, v, size=batch_size)\n",
        "        fixed_images = d[idx2, ..., np.newaxis]\n",
        "        fixed_images=fixed_images/m\n",
        "\n",
        "\n",
        "        moving_images=[]\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            moving_images.append(augsb(fixed_images,i,y[i]))\n",
        "\n",
        "        moving_images=np.array(moving_images)    \n",
        "        moving_images=moving_images[... , np.newaxis]\n",
        "\n",
        "\n",
        "\n",
        "        #moving_images=augsb(fixed_images,y)\n",
        "\n",
        "        #idx1 = np.random.randint(0, v, size=batch_size)\n",
        "        #moving_images = d[idx1, ..., np.newaxis]\n",
        "        #moving_images=moving_images/m\n",
        "        inputs = [moving_images, fixed_images]\n",
        "\n",
        "        # prepare outputs (the 'true' moved image):\n",
        "        # of course, we don't have this, but we know we want to compare \n",
        "        # the resulting moved image with the fixed image. \n",
        "        # we also wish to penalize the deformation field. \n",
        "        outputs = [fixed_images,zero_phi]\n",
        "\n",
        "        yield(inputs,outputs)\n",
        "    #y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oge_4uVqwDbp"
      },
      "outputs": [],
      "source": [
        "def label_generator(data_dir,batch_size,m,split):\n",
        "\n",
        "    n,train_data_num=count(data_dir)\n",
        "    n_train=n-int(split*n)\n",
        "    a=n_train\n",
        "\n",
        "\n",
        "    subject_ID=random.randint(a,n-1)\n",
        "    d=load_m(data_dir+'/'+str(train_data_num[subject_ID][0]))\n",
        "\n",
        "\n",
        "    s=d.shape[2]\n",
        "    slice_ID =random.randint(0,s-1)\n",
        "\n",
        "    v=d.shape[3]\n",
        "\n",
        "    # preliminary sizing\n",
        "    vol_shape = d.shape[:2] # extract data shape\n",
        "    ndims = len(vol_shape)\n",
        "\n",
        "\n",
        "    d=d[:,:,slice_ID,:]\n",
        "    d = np.einsum('jki->ijk', d)\n",
        "\n",
        "\n",
        "    y=[]\n",
        "    for i in range(batch_size):\n",
        "        y.append(affine_matrix())\n",
        "    y=np.array(y)\n",
        "\n",
        "\n",
        "    # prepare a zero array the size of the deformation\n",
        "    # we'll explain this below\n",
        "\n",
        "    # prepare inputs:\n",
        "    # images need to be of the size [batch_size, H, W, 1]\n",
        "    while True:\n",
        "\n",
        "        idx2 = np.random.randint(0, v, size=batch_size)\n",
        "        fixed_images = d[idx2, ...]\n",
        "        fixed_images=fixed_images/m\n",
        "\n",
        "\n",
        "        moving_images=[]\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            moving_images.append(augsb(fixed_images,i,y[i]))\n",
        "        moving_images=np.array(moving_images)    \n",
        "        #moving_images=moving_images[... ]\n",
        "        \n",
        "        \n",
        "        c=np.stack([moving_images,fixed_images], axis=2) \n",
        "        inputs = [c]\n",
        "        #inputs=[[moving_images,fixed_images]]\n",
        "        \n",
        "        # prepare outputs (the 'true' moved image):\n",
        "        # of course, we don't have this, but we know we want to compare \n",
        "        # the resulting moved image with the fixed image. \n",
        "        # we also wish to penalize the deformation field.\n",
        "\n",
        "        outputs = [y]\n",
        "        yield (inputs, outputs)\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mCdfzzuwDbq"
      },
      "outputs": [],
      "source": [
        "def ref(data_dir,m,slice_ID,reference):\n",
        "    \"\"\"4\n",
        "    Generator that takes in data of size [N, H, W], and yields data for\n",
        "    our custom vxm model. Note that we need to provide numpy data for each\n",
        "    input, and each output.\n",
        "\n",
        "    inputs:  moving [bs, H, W, 1], fixed image [bs, H, W, 1]\n",
        "    outputs: moved image [bs, H, W, 1], zero-gradient [bs, H, W, 2]\n",
        "    \n",
        "    m= maximum between all subject \n",
        "    split= percent of validation data\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "   \n",
        "    d=load_m(data_dir)\n",
        "    \n",
        "    #s=d.shape[2]\n",
        "    #slice_ID =random.randint(0,s-1)\n",
        "    v=d.shape[3]\n",
        "    \n",
        " # preliminary sizing\n",
        "    vol_shape = d.shape[:2] # extract data shape\n",
        "    ndims = len(vol_shape)\n",
        "    \n",
        "    \n",
        "    d=d[:,:,slice_ID,:]\n",
        "    d = np.einsum('jki->ijk', d)\n",
        "\n",
        "    \n",
        "    \n",
        "   \n",
        "    \n",
        "    # prepare a zero array the size of the deformation\n",
        "    # we'll explain this below\n",
        "    zero_phi = np.zeros([v, *vol_shape, ndims])\n",
        "    \n",
        "    # prepare inputs:\n",
        "    # images need to be of the size [batch_size, H, W, 1]\n",
        "    idx1=[]\n",
        "    for i in range(v):\n",
        "\n",
        "        idx1.append(i)\n",
        "        \n",
        "    idx1=np.array(idx1)    \n",
        "    moving_images = d[idx1, ..., np.newaxis]\n",
        "    moving_images=moving_images/m\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    if reference.strip().isdigit():\n",
        "        # print(\"User input is Number\")\n",
        "        reference=int(reference)\n",
        "        idx2=np.ones(v)*reference\n",
        "        idx2=idx2.astype(int)\n",
        "\n",
        "        fixed_images = d[idx2, ..., np.newaxis]\n",
        "        fixed_images=fixed_images/m\n",
        "\n",
        "\n",
        "    else:\n",
        "        # print(\"User input is string\")\n",
        "\n",
        "\n",
        "        img = nib.load(reference)\n",
        "        img_data = img.get_fdata()\n",
        "        if img.shape[0:2]!=(64,64):\n",
        "            img_data = img_data[23:87,23:87,:]\n",
        "            \n",
        "        img_data=img_data[np.newaxis,:,:,slice_ID]\n",
        "        idx2=np.zeros(v)\n",
        "        idx2=idx2.astype(int)\n",
        "\n",
        "        fixed_images = img_data[idx2, ..., np.newaxis]\n",
        "        fixed_images=fixed_images/m\n",
        "\n",
        "        \n",
        "    inputs = [moving_images, fixed_images]\n",
        "\n",
        "    # prepare outputs (the 'true' moved image):\n",
        "    # of course, we don't have this, but we know we want to compare \n",
        "    # the resulting moved image with the fixed image. \n",
        "    # we also wish to penalize the deformation field. \n",
        "    outputs = [fixed_images,zero_phi]\n",
        "\n",
        "    return (inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk8DCh7IwDbr"
      },
      "outputs": [],
      "source": [
        "def main (input_direction,reference,output_direction,maximum_intensity,loadable_model):\n",
        "\n",
        "    start_time = time.time()\n",
        "    img_data,img=load_with_head(input_direction)\n",
        "    slice_number = img_data.shape[2]\n",
        "    header=img.header\n",
        "    img_mask_affine = img.affine\n",
        "        # configure unet input shape (concatenation of moving and fixed images)\n",
        "    ndim = 2\n",
        "    unet_input_features = 2\n",
        "    # data shape 64*64\n",
        "    s=(64,64)\n",
        "    inshape = (*s, unet_input_features)\n",
        "    # configure unet features \n",
        "    nb_features =[\n",
        "        [64, 64, 64, 64],         # encoder features\n",
        "        [64, 64, 64, 64, 64, 32,16]  # decoder features\n",
        "                 ]\n",
        "    # build model using VxmDense\n",
        "    inshape =s\n",
        "    vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)\n",
        "    # voxelmorph has a variety of custom loss classes\n",
        "    losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
        "    # usually, we have to balance the two losses by a hyper-parameter\n",
        "    lambda_param = 0.05\n",
        "    loss_weights = [1, lambda_param]\n",
        "    vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights, metrics=['accuracy'])\n",
        "    vxm_model.load_weights(loadable_model)\n",
        "    o=np.zeros((img_data.shape[0],img_data.shape[1],img_data.shape[2],img_data.shape[3]))\n",
        "\n",
        "    for i in range(slice_number):\n",
        "\n",
        "        prepare_data=ref(input_direction,maximum_intensity,i,reference)\n",
        "        val_input, _ = prepare_data\n",
        "        val_pred = vxm_model.predict(val_input)\n",
        "        change_order= np.einsum('jki->kij',val_pred[0][:,:,:,0])\n",
        "\n",
        "        o[:, :, i,:] = change_order\n",
        "\n",
        "\n",
        "    img_reg = nib.Nifti1Image(o*maximum_intensity, affine=img_mask_affine, header=header)\n",
        "    nib.save(img_reg,output_direction)   \n",
        "    print(\"--- %s second ---\" % (time.time() - start_time))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G5wj8zVwDbr"
      },
      "outputs": [],
      "source": [
        "def snr (direction):\n",
        "    \n",
        "    img = nib.load(direction)\n",
        "    img = img.get_fdata()\n",
        "    mean=[]\n",
        "    \n",
        "    for i in range(img.shape[2]):\n",
        "        mean.append(np.mean(img[:,:,i]))\n",
        "    mean=np.array(mean)\n",
        "    \n",
        "    deviation=[]\n",
        "    for i in range(img.shape[2]):\n",
        "        deviation.append(np.std(img[:,:,i]))\n",
        "    deviation=np.array(deviation)\n",
        "    \n",
        "    \n",
        "    return (mean/deviation),mean,deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4PFK3eqwDbr"
      },
      "outputs": [],
      "source": [
        "def mean(direction): \n",
        "    img = nib.load(direction)\n",
        "    img = img.get_fdata()\n",
        "    mean=[]\n",
        "    where_are_NaNs = isnan(img)\n",
        "    img[where_are_NaNs] = 0\n",
        "    \n",
        "    for i in range(img.shape[2]):\n",
        "        mean.append(np.mean(img[:,:,i]))\n",
        "    mean.append(np.mean(mean))    \n",
        "    mean=np.array(mean)\n",
        "    return mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-Ddi4UiwDbs"
      },
      "outputs": [],
      "source": [
        "def seg_mean(img):\n",
        "    p=0\n",
        "    for m in range(img.shape[0]):\n",
        "        for n in range(img.shape[1]):\n",
        "            if img[m,n]==0:\n",
        "                p=p+1\n",
        "            s=np.sum(img[:,:])\n",
        "    mean=s/((64*64)-p)   \n",
        "    return mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS4pHS5ewDbs"
      },
      "outputs": [],
      "source": [
        "def mean_all(direction): \n",
        "    img = nib.load(direction)\n",
        "    img = img.get_fdata()\n",
        "    mean=[]\n",
        "    where_are_NaNs = np.isnan(img)\n",
        "    img[where_are_NaNs] = 0\n",
        "    \n",
        "    for i in range(img.shape[2]):\n",
        "        mean.append(seg_mean(img[:,:,i]))\n",
        "     \n",
        "    mean=np.mean(mean) \n",
        "    return mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2CrhV3ewDbs"
      },
      "outputs": [],
      "source": [
        "def shift_image(X, dx, dy):\n",
        "    X = np.roll(X, dy, axis=0)\n",
        "    X = np.roll(X, dx, axis=1)\n",
        "    if dy>0:\n",
        "        X[:dy, :] = 0\n",
        "    elif dy<0:\n",
        "        X[dy:, :] = 0\n",
        "    if dx>0:\n",
        "        X[:, :dx] = 0\n",
        "    elif dx<0:\n",
        "        X[:, dx:] = 0\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoNiNXr_wDbs"
      },
      "outputs": [],
      "source": [
        "def cplus(source_centerline_directory,centerlines_directory,main_data_directory,\n",
        "          center_fix_directory,final_cplus_directory,\n",
        "           maximum_intensity,model,reference,mean_directory\n",
        "         ):\n",
        "\n",
        "    #############################################\n",
        "    # if reference=0 means reference=first volume\n",
        "    # if reference=-1 means reference=mid volume\n",
        "    # if reference=-2 means reference=mean volume\n",
        "    # if reference>0 means reference=any volume\n",
        "\n",
        "\n",
        "        Xs=[]\n",
        "        Ys=[]\n",
        "        source = pd.read_csv(source_centerline_directory, header=None)\n",
        "        source.columns=['x','y','delete']\n",
        "        source = source[['x','y']]\n",
        "\n",
        "        for s in range(source.shape[0]):\n",
        "            c=source.loc[s]\n",
        "            #xs=int(c['x'])\n",
        "            ys=int(c['y'])\n",
        "            #Xs.append(xs)\n",
        "            Ys.append(ys)\n",
        "\n",
        "        n2,name2=count_endwith(centerlines_directory,'.csv')\n",
        "\n",
        "        dx=[]\n",
        "        dy=[]\n",
        "        for s in range(0,source.shape[0]):\n",
        "             for j in range(n2):\n",
        "                    df = pd.read_csv(centerlines_directory+name2[j][0], header=None)\n",
        "                    df.columns=['x','y','delete']\n",
        "                    df=df[['x','y']]\n",
        "                    c=df.loc[s]\n",
        "                    #x=int(c['x'])\n",
        "                    y=int(c['y'])\n",
        "                    #dx.append(Xs[s]-x)\n",
        "                    dy.append(Ys[s]-y)  \n",
        "\n",
        "        input_direction=main_data_directory\n",
        "        img  = nib.load(input_direction)\n",
        "        img_data=img.get_fdata()\n",
        "        img_mask_affine = img.affine\n",
        "        header = img.header\n",
        "        nb_img = header.get_data_shape()\n",
        "        o=np.zeros((nb_img[0],nb_img[1],nb_img[2],nb_img[3]))\n",
        "\n",
        "\n",
        "        DX=np.zeros(len(dy))\n",
        "\n",
        "\n",
        "        start=0            \n",
        "        for s in range(0,source.shape[0]):\n",
        "            for v in range(n2):\n",
        "                        a= shift_image(img_data[:,:,s,v],dy[v+start],DX[v+start])\n",
        "                        o[:,:,s, v] = a            \n",
        "            start=start + n2\n",
        "\n",
        "       \n",
        "        input_direction=center_fix_directory\n",
        "        img_reg = nib.Nifti1Image(o, affine=img_mask_affine, header=header)\n",
        "        nib.save(img_reg,input_direction)\n",
        "       \n",
        "        if reference>0:\n",
        "            reference=str(reference)\n",
        "        if reference==0:\n",
        "            reference='0'\n",
        "        if reference==-1:\n",
        "            y=int(n2/2)\n",
        "            reference=str(y)\n",
        "        if reference==-2:\n",
        "            reference=mean_directory\n",
        "        \n",
        "\n",
        "        main(input_direction,reference,final_cplus_directory,maximum_intensity,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTt5ddkVwDbt"
      },
      "outputs": [],
      "source": [
        "def count_startwith (data_dir,prefix):\n",
        "    train_dir = os.path.join(data_dir)\n",
        "\n",
        "    train_data_num = []\n",
        "    for file in os.listdir(train_dir):\n",
        "        if file.startswith(prefix):\n",
        "            train_data_num.append([file])\n",
        "    train_data_num=np.array(train_data_num) \n",
        "    n=train_data_num.shape[0] \n",
        "\n",
        "    return n,sorted(train_data_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAv5tB1MwDbt"
      },
      "outputs": [],
      "source": [
        "def count_endwith (data_dir,prefix):\n",
        "    train_dir = os.path.join(data_dir)\n",
        "\n",
        "    train_data_num = []\n",
        "    for file in os.listdir(train_dir):\n",
        "        if file.endswith(prefix):\n",
        "            train_data_num.append([file])\n",
        "    train_data_num=np.array(train_data_num) \n",
        "    n=train_data_num.shape[0] \n",
        "\n",
        "    return n,sorted(train_data_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mdNJg-owDbt"
      },
      "source": [
        "# movement plots for one slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvS66Hi-wDbu"
      },
      "outputs": [],
      "source": [
        "def flow_one_slice(input_direction,reference,maximum_intensity,loadable_model,slice_num,mean_directory,title):\n",
        "    img_data,img=load_with_head(input_direction)\n",
        "    slice_number = img_data.shape[2]\n",
        "    header=img.header\n",
        "    img_mask_affine = img.affine\n",
        "        # configure unet input shape (concatenation of moving and fixed images)\n",
        "    ndim = 2\n",
        "    unet_input_features = 2\n",
        "    # data shape 64*64\n",
        "    s=(64,64)\n",
        "    inshape = (*s, unet_input_features)\n",
        "    # configure unet features \n",
        "    nb_features =[\n",
        "        [64, 64, 64, 64],         # encoder features\n",
        "        [64, 64, 64, 64, 64, 32,16]  # decoder features\n",
        "                 ]\n",
        "    # build model using VxmDense\n",
        "    inshape =s\n",
        "    vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)\n",
        "    # voxelmorph has a variety of custom loss classes\n",
        "    losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
        "    # usually, we have to balance the two losses by a hyper-parameter\n",
        "    lambda_param = 0.05\n",
        "    loss_weights = [1, lambda_param]\n",
        "    vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights, metrics=['accuracy'])\n",
        "    vxm_model.load_weights(loadable_model)\n",
        "\n",
        "    if reference>0:\n",
        "        reference=str(reference)\n",
        "    if reference==0:\n",
        "        reference='0'\n",
        "    if reference==-1:\n",
        "        y=int(img_data.shape[3]/2)\n",
        "        reference=str(y)\n",
        "    if reference==-2:\n",
        "        reference=mean_directory\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #for i in range(slice_number):\n",
        "    #slice_number=5\n",
        "    prepare_data=ref(input_direction,maximum_intensity,slice_num,reference)\n",
        "    val_input, _ = prepare_data\n",
        "    val_pred = vxm_model.predict(val_input)\n",
        "    #val_pred=flow(input_direction,reference,maximum_intensity,loadable_model,slice_num)\n",
        "  \n",
        "    x=[]\n",
        "    y=[]\n",
        "    for i in range(val_pred[1][:,0,0,0].shape[0]):\n",
        "        x.append(np.mean(val_pred[1][i,...,0]))\n",
        "        y.append(np.mean(val_pred[1][i,...,1]))\n",
        "    x=np.array(x)\n",
        "    y=np.array(y)\n",
        "\n",
        "    volume=range(val_pred[1][:,0,0,0].shape[0])\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.plot(volume,x,label = \"x\")\n",
        "    plt.plot(volume,y,label = \"y\")\n",
        "    # naming the x axis\n",
        "    plt.xlabel('volumes')\n",
        "    # naming the y axis\n",
        "    plt.ylabel('movement')\n",
        "    # giving a title to my graph\n",
        "    plt.title(title)\n",
        "\n",
        "    # show a legend on the plot\n",
        "    plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieJFGCg7wDbu"
      },
      "source": [
        "# movement plot for all slice in one plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT4XSJWEwDbu"
      },
      "outputs": [],
      "source": [
        "def flow_all_slice(input_direction,reference,maximum_intensity,loadable_model,mean_directory,title):\n",
        "    img_data,img=load_with_head(input_direction)\n",
        "    slice_number = img_data.shape[2]\n",
        "    header=img.header\n",
        "    img_mask_affine = img.affine\n",
        "        # configure unet input shape (concatenation of moving and fixed images)\n",
        "    ndim = 2\n",
        "    unet_input_features = 2\n",
        "    # data shape 64*64\n",
        "    s=(64,64)\n",
        "    inshape = (*s, unet_input_features)\n",
        "    # configure unet features \n",
        "    nb_features =[\n",
        "        [64, 64, 64, 64],         # encoder features\n",
        "        [64, 64, 64, 64, 64, 32,16]  # decoder features\n",
        "                 ]\n",
        "    # build model using VxmDense\n",
        "    inshape =s\n",
        "    vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)\n",
        "    # voxelmorph has a variety of custom loss classes\n",
        "    losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
        "    # usually, we have to balance the two losses by a hyper-parameter\n",
        "    lambda_param = 0.05\n",
        "    loss_weights = [1, lambda_param]\n",
        "    vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights, metrics=['accuracy'])\n",
        "    vxm_model.load_weights(loadable_model)\n",
        "\n",
        "    if reference>0:\n",
        "        reference=str(reference)\n",
        "    if reference==0:\n",
        "        reference='0'\n",
        "    if reference==-1:\n",
        "        y=int(img_data.shape[3]/2)\n",
        "        reference=str(y)\n",
        "    if reference==-2:\n",
        "        reference=mean_directory\n",
        "\n",
        "    \n",
        "   \n",
        "    x_all_slice=[]\n",
        "    y_all_slice=[]\n",
        "    \n",
        "    for i in range(slice_number):\n",
        "        prepare_data=ref(input_direction,maximum_intensity,i,reference)\n",
        "        val_input, _ = prepare_data\n",
        "        val_pred = vxm_model.predict(val_input)\n",
        "        #val_pred=flow(input_direction,reference,maximum_intensity,loadable_model,slice_num)\n",
        "        x=[]\n",
        "        y=[]\n",
        "        \n",
        "        for i in range(val_pred[1][:,0,0,0].shape[0]):\n",
        "            x.append(np.mean(val_pred[1][i,...,0]))\n",
        "            y.append(np.mean(val_pred[1][i,...,1]))\n",
        "\n",
        "        x_all_slice.append(x)\n",
        "        y_all_slice.append(y)\n",
        "\n",
        "\n",
        "    \n",
        "    x_all_slice=np.array(x_all_slice)\n",
        "    y_all_slice=np.array(y_all_slice)\n",
        "    \n",
        "    mean_x=x_all_slice.mean(axis=0)\n",
        "    mean_y=y_all_slice.mean(axis=0)\n",
        "    ### for delete the eror for reference to reference\n",
        "    mean_x[int(reference)]=0\n",
        "    mean_y[int(reference)]=0\n",
        "    \n",
        "    \n",
        "    overal=(mean_x+mean_y)/2\n",
        "    \n",
        "    volume=range(val_pred[1][:,0,0,0].shape[0])\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.plot(volume,overal,label = \"x\")\n",
        "    #plt.plot(volume,mean_y,label = \"y\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # naming the x axis\n",
        "    plt.xlabel('volumes')\n",
        "    # naming the y axis\n",
        "    plt.ylabel('movement')\n",
        "    # giving a title to my graph\n",
        "    plt.title(title)\n",
        "\n",
        "    # show a legend on the plot\n",
        "    plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VPD6EHkwDbu"
      },
      "outputs": [],
      "source": [
        "def flow_between_two(input_direction0,input_direction1,reference,\n",
        "                     maximum_intensity,loadable_model,mean_directory,\n",
        "                     title,label1,label2):\n",
        "  \n",
        "    img_data,img=load_with_head(input_direction0)\n",
        "    slice_number = img_data.shape[2]\n",
        "    header=img.header\n",
        "    img_mask_affine = img.affine\n",
        "        # configure unet input shape (concatenation of moving and fixed images)\n",
        "    ndim = 2\n",
        "    unet_input_features = 2\n",
        "    # data shape 64*64\n",
        "    s=(64,64)\n",
        "    inshape = (*s, unet_input_features)\n",
        "    # configure unet features \n",
        "    nb_features =[\n",
        "        [64, 64, 64, 64],         # encoder features\n",
        "        [64, 64, 64, 64, 64, 32,16]  # decoder features\n",
        "                 ]\n",
        "    # build model using VxmDense\n",
        "    inshape =s\n",
        "    vxm_model = vxm.networks.VxmDense(inshape, nb_features, int_steps=0)\n",
        "    # voxelmorph has a variety of custom loss classes\n",
        "    losses = [vxm.losses.MSE().loss, vxm.losses.Grad('l2').loss]\n",
        "    # usually, we have to balance the two losses by a hyper-parameter\n",
        "    lambda_param = 0.05\n",
        "    loss_weights = [1, lambda_param]\n",
        "    vxm_model.compile(optimizer='Adam', loss=losses, loss_weights=loss_weights, metrics=['accuracy'])\n",
        "    vxm_model.load_weights(loadable_model)\n",
        "\n",
        "    if reference>0:\n",
        "        reference=str(reference)\n",
        "    if reference==0:\n",
        "        reference='0'\n",
        "    if reference==-1:\n",
        "        y=int(img_data.shape[3]/2)\n",
        "        reference=str(y)\n",
        "    if reference==-2:\n",
        "        reference=mean_directory\n",
        "\n",
        "    \n",
        "   \n",
        "    x_all_slice=[]\n",
        "    y_all_slice=[]\n",
        "    \n",
        "    for i in range(slice_number):\n",
        "        prepare_data=ref(input_direction0,maximum_intensity,i,reference)\n",
        "        val_input, _ = prepare_data\n",
        "        val_pred = vxm_model.predict(val_input)\n",
        "        #val_pred=flow(input_direction,reference,maximum_intensity,loadable_model,slice_num)\n",
        "        x=[]\n",
        "        y=[]\n",
        "        \n",
        "        for i in range(val_pred[1][:,0,0,0].shape[0]):\n",
        "            x.append(np.mean(val_pred[1][i,...,0]))\n",
        "            y.append(np.mean(val_pred[1][i,...,1]))\n",
        "\n",
        "        x_all_slice.append(x)\n",
        "        y_all_slice.append(y)\n",
        "\n",
        "\n",
        "    \n",
        "    x_all_slice=np.array(x_all_slice)\n",
        "    y_all_slice=np.array(y_all_slice)\n",
        "    \n",
        "    mean_x=x_all_slice.mean(axis=0)\n",
        "    mean_y=y_all_slice.mean(axis=0)\n",
        "    ### for delete the eror for reference to reference\n",
        "    mean_x[int(reference)]=0\n",
        "    mean_y[int(reference)]=0\n",
        "    \n",
        "    \n",
        "    overal=(mean_x+mean_y)/2\n",
        "   \n",
        "\n",
        "   \n",
        "   \n",
        "    x_all_slice=[]\n",
        "    y_all_slice=[]\n",
        "    \n",
        "    for i in range(slice_number):\n",
        "        prepare_data=ref(input_direction1,maximum_intensity,i,reference)\n",
        "        val_input, _ = prepare_data\n",
        "        val_pred = vxm_model.predict(val_input)\n",
        "        #val_pred=flow(input_direction,reference,maximum_intensity,loadable_model,slice_num)\n",
        "        x=[]\n",
        "        y=[]\n",
        "        \n",
        "        for i in range(val_pred[1][:,0,0,0].shape[0]):\n",
        "            x.append(np.mean(val_pred[1][i,...,0]))\n",
        "            y.append(np.mean(val_pred[1][i,...,1]))\n",
        "\n",
        "        x_all_slice.append(x)\n",
        "        y_all_slice.append(y)\n",
        "\n",
        "\n",
        "    \n",
        "    x_all_slice=np.array(x_all_slice)\n",
        "    y_all_slice=np.array(y_all_slice)\n",
        "    \n",
        "    mean_x=x_all_slice.mean(axis=0)\n",
        "    mean_y=y_all_slice.mean(axis=0)\n",
        "    ### for delete the eror for reference to reference\n",
        "    mean_x[int(reference)]=0\n",
        "    mean_y[int(reference)]=0\n",
        "    \n",
        "    \n",
        "    overal1=(mean_x+mean_y)/2    \n",
        "\n",
        "\n",
        " \n",
        "    volume=range(val_pred[1][:,0,0,0].shape[0])\n",
        "    \n",
        "    plt.figure(figsize=(25,10))\n",
        "    plt.plot(volume,overal,label = label1)\n",
        "    plt.plot(volume,overal1,label = label2)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # naming the x axis\n",
        "    plt.xlabel('volumes',fontsize=18)\n",
        "    # naming the y axis\n",
        "    plt.ylabel('movement',fontsize=18)\n",
        "    # giving a title to my graph\n",
        "    plt.title(title,fontsize=20)\n",
        "\n",
        "    # show a legend on the plot\n",
        "    plt.xticks(fontsize=15)\n",
        "    plt.yticks(fontsize=15)\n",
        "    # show a legend on the plot\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.legend(fontsize=15)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNudvJYzwDbv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "functions.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}